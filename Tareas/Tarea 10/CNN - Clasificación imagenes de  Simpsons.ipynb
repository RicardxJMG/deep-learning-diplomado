{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/MyDrive/datasets/\"\n",
        "SELECTED_ZIP_FILENAME = \"mis_simpson_final.zip\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53lxSnAqrFe8",
        "outputId": "3b87d927-8af3-41bc-ead0-6d5ece1f02f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# NOTEBOOK: Clasificación de IMÁGENES + CNN\n",
        "# Robustez: split por archivos, class_weight automático, OOM-safe (T4),\n",
        "#           persistencia (weights.best.keras)\n",
        "#\n",
        "# ENTRADA:\n",
        "#   1) Subes un ZIP manualmente al runtime de Colab (/content/*.zip)\n",
        "#   2) Estructura interna del ZIP (recomendado):\n",
        "#        <raiz>/\n",
        "#          clase_0/   (jpg/png/...)\n",
        "#          clase_1/\n",
        "#          ...\n",
        "#\n",
        "# SALIDAS:\n",
        "#   - weights.best.keras\n",
        "# ============================================================\n",
        "\n",
        "# =========================\n",
        "# CELDA 0 — CONFIG GLOBAL + carga de DATA_DIR desde Google Drive\n",
        "# Supuesto: El usuario ya ha montado Google Drive y definido la variable 'path'.\n",
        "# =========================\n",
        "import os, glob, zipfile, shutil, random, math, time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# -------------------------\n",
        "# 1) CONFIGURACIÓN GENERAL (SOLO IMAGEN)\n",
        "# -------------------------\n",
        "\n",
        "WORKDIR = \"/content/dataset\" # La carpeta local para el dataset descomprimido\n",
        "CLEAN_WORKDIR = True # Limpiar la carpeta antes de descomprimir\n",
        "\n",
        "# Ubicación en Drive donde se espera encontrar los archivos ZIP del dataset\n",
        "DRIVE_DATA_SOURCE = os.path.join(path, 'simpsons')\n",
        "\n",
        "SEED = 123\n",
        "TRAIN_FRAC = 0.60\n",
        "VAL_FRAC   = 0.20\n",
        "TEST_FRAC  = 0.20\n",
        "\n",
        "AUTO = True\n",
        "IMG_SIZE_MANUAL = (128, 128)   # si AUTO=False\n",
        "BATCH_MANUAL    = 32           # si AUTO=False\n",
        "\n",
        "# -------------------------\n",
        "# 2) OPTIMIZACIÓN GPU T4\n",
        "# -------------------------\n",
        "USE_MIXED_PRECISION = True\n",
        "if USE_MIXED_PRECISION:\n",
        "    try:\n",
        "        from tensorflow.keras import mixed_precision\n",
        "        mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "        print(\"Mixed precision activada:\", mixed_precision.global_policy())\n",
        "    except Exception as e:\n",
        "        print(\"No se pudo activar mixed precision:\", e)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# -------------------------\n",
        "# 3) DETECTAR ZIP EN DRIVE Y COPIAR/DESCOMPRIMIR\n",
        "# -------------------------\n",
        "# Usar SELECTED_ZIP_FILENAME definido en la celda anterior\n",
        "zip_name_full_path = os.path.join(DRIVE_DATA_SOURCE, SELECTED_ZIP_FILENAME)\n",
        "assert os.path.exists(zip_name_full_path), f\"No se encontró el archivo ZIP '{SELECTED_ZIP_FILENAME}' en {DRIVE_DATA_SOURCE}.\"\n",
        "zip_base_name = os.path.basename(zip_name_full_path)\n",
        "\n",
        "print(\"ZIP seleccionado en Drive:\", zip_base_name)\n",
        "print(\"Última modificación:\", time.ctime(os.path.getmtime(zip_name_full_path)))\n",
        "\n",
        "# -------------------------\n",
        "# 4) PREPARAR WORKDIR Y DESCOMPRIMIR\n",
        "# -------------------------\n",
        "if CLEAN_WORKDIR and os.path.isdir(WORKDIR):\n",
        "    shutil.rmtree(WORKDIR)\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "\n",
        "print(f\"Descomprimiendo {zip_base_name} en {WORKDIR}...\")\n",
        "with zipfile.ZipFile(zip_name_full_path, \"r\") as z:\n",
        "    z.extractall(WORKDIR)\n",
        "\n",
        "print(\"Dataset descomprimido en:\", WORKDIR)\n",
        "!ls -lah \"{WORKDIR}\"\n",
        "\n",
        "# -------------------------\n",
        "# 5) AUTODETECTAR DATA_DIR REAL\n",
        "#   buscamos una carpeta que contenga subcarpetas con archivos válidos\n",
        "# -------------------------\n",
        "def find_data_root_images(workdir):\n",
        "    exts = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n",
        "\n",
        "    candidates = [workdir]\n",
        "    candidates += [os.path.join(workdir, d) for d in os.listdir(workdir) if os.path.isdir(os.path.join(workdir, d))]\n",
        "\n",
        "    def score_dir(d):\n",
        "        if not os.path.isdir(d):\n",
        "            return -1, 0, 0\n",
        "        subdirs = [os.path.join(d, s) for s in os.listdir(d) if os.path.isdir(os.path.join(d, s))]\n",
        "        if not subdirs:\n",
        "            return -1, 0, 0\n",
        "\n",
        "        good_folders = 0\n",
        "        total_files = 0\n",
        "        for sd in subdirs:\n",
        "            n = 0\n",
        "            for ext in exts:\n",
        "                n += len(glob.glob(os.path.join(sd, f\"*{ext}\")))\n",
        "            if n > 0:\n",
        "                good_folders += 1\n",
        "                total_files += n\n",
        "        return good_folders, total_files, len(subdirs)\n",
        "\n",
        "    best = None\n",
        "    best_score = (-1, -1, -1)\n",
        "    for c in candidates:\n",
        "        sc = score_dir(c)\n",
        "        if sc > best_score:\n",
        "            best_score = sc\n",
        "            best = c\n",
        "\n",
        "    if best is None or best_score[0] < 2:\n",
        "        # Si el WORKDIR mismo es la raíz con carpetas de clases, también es válido.\n",
        "        workdir_score = score_dir(workdir)\n",
        "        if workdir_score[0] >= 2:\n",
        "            return workdir, workdir_score\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"No pude detectar una raíz de dataset válida.\\n\"\n",
        "                \"Asegúrate de que la carpeta descomprimida (en /content/dataset) contenga subcarpetas \"\n",
        "                \"con archivos de imagen (ej. 'clase_0/', 'clase_1/').\\n\"\n",
        "                f\"WORKDIR={workdir}\"\n",
        "            )\n",
        "\n",
        "    return best, best_score\n",
        "\n",
        "DATA_DIR, sc = find_data_root_images(WORKDIR)\n",
        "\n",
        "print(\"\\nCONFIG FINAL:\")\n",
        "print(\"  WORKDIR   :\", WORKDIR)\n",
        "print(\"  DATA_DIR  :\", DATA_DIR)\n",
        "print(\"  (folders_con_archivos, total_archivos, subcarpetas):\", sc)\n",
        "print(\"  GPU       :\", tf.config.list_physical_devices(\"GPU\"))\n"
      ],
      "metadata": {
        "id": "ugkPYVSui6KQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03b5a977-4fd5-49ce-aacb-e42f267e0ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mixed precision activada: <DTypePolicy \"mixed_float16\">\n",
            "ZIP seleccionado en Drive: mis_simpson_final.zip\n",
            "Última modificación: Sun Jan 11 01:28:29 2026\n",
            "Descomprimiendo mis_simpson_final.zip en /content/dataset...\n",
            "Dataset descomprimido en: /content/dataset\n",
            "total 12K\n",
            "drwxr-xr-x  3 root root 4.0K Jan 20 23:43 .\n",
            "drwxr-xr-x  1 root root 4.0K Jan 20 23:43 ..\n",
            "drwxr-xr-x 16 root root 4.0K Jan 20 23:44 simpsons_dataset\n",
            "\n",
            "CONFIG FINAL:\n",
            "  WORKDIR   : /content/dataset\n",
            "  DATA_DIR  : /content/dataset/simpsons_dataset\n",
            "  (folders_con_archivos, total_archivos, subcarpetas): (14, 17210, 14)\n",
            "  GPU       : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "#@title ## CELDA 1 — UTILIDADES: CLASES + SPLIT + DESBALANCE + VALIDACIÓN FUERTE (IMAGEN)\n",
        "# ======================================\n",
        "import numpy as np\n",
        "import os, glob\n",
        "\n",
        "def list_class_folders(data_dir):\n",
        "    classes = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
        "    if len(classes) < 2:\n",
        "        raise ValueError(f\"Se requieren >=2 subcarpetas en: {data_dir}. Encontré: {classes}\")\n",
        "    return classes\n",
        "\n",
        "def list_files_by_class_image(data_dir):\n",
        "    classes = list_class_folders(data_dir)\n",
        "    exts = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n",
        "\n",
        "    files = []\n",
        "    labels = []\n",
        "    per_class = []\n",
        "\n",
        "    for i, cls in enumerate(classes):\n",
        "        cls_dir = os.path.join(data_dir, cls)\n",
        "        cls_files = []\n",
        "        for ext in exts:\n",
        "            cls_files.extend(glob.glob(os.path.join(cls_dir, f\"*{ext}\")))\n",
        "        cls_files = sorted(cls_files)\n",
        "\n",
        "        per_class.append((cls, len(cls_files)))\n",
        "        files.extend(cls_files)\n",
        "        labels.extend([i]*len(cls_files))\n",
        "\n",
        "    return classes, np.array(files), np.array(labels, dtype=np.int32), per_class\n",
        "\n",
        "def stratified_split(files, labels, train_frac, val_frac, test_frac, seed=123):\n",
        "    assert abs(train_frac + val_frac + test_frac - 1.0) < 1e-9\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx = np.arange(len(files))\n",
        "\n",
        "    train_idx, val_idx, test_idx = [], [], []\n",
        "    for c in np.unique(labels):\n",
        "        c_idx = idx[labels == c]\n",
        "        rng.shuffle(c_idx)\n",
        "        n = len(c_idx)\n",
        "        if n == 0:\n",
        "            continue\n",
        "\n",
        "        n_train = int(round(n * train_frac))\n",
        "        n_val   = int(round(n * val_frac))\n",
        "\n",
        "        n_train = max(1, min(n_train, n))\n",
        "        n_val = min(n_val, n - n_train)\n",
        "\n",
        "        train_idx.extend(c_idx[:n_train])\n",
        "        val_idx.extend(c_idx[n_train:n_train+n_val])\n",
        "        test_idx.extend(c_idx[n_train+n_val:])\n",
        "\n",
        "    rng.shuffle(train_idx); rng.shuffle(val_idx); rng.shuffle(test_idx)\n",
        "    # Asegurar que los arrays de salida sean de tipo entero\n",
        "    return np.array(train_idx, dtype=np.int64), np.array(val_idx, dtype=np.int64), np.array(test_idx, dtype=np.int64)\n",
        "\n",
        "def compute_class_weight(train_labels, num_classes):\n",
        "    counts = np.bincount(train_labels, minlength=num_classes).astype(np.int64)\n",
        "    N = counts.sum()\n",
        "    weights = {}\n",
        "    for c in range(num_classes):\n",
        "        weights[c] = 0.0 if counts[c] == 0 else float(N) / float(num_classes * counts[c])\n",
        "    return counts, weights\n",
        "\n",
        "# -------------------------\n",
        "# CARGA (IMAGEN)\n",
        "# -------------------------\n",
        "classes, all_files, all_labels, per_class = list_files_by_class_image(DATA_DIR)\n",
        "num_classes = len(classes)\n",
        "\n",
        "train_idx, val_idx, test_idx = stratified_split(all_files, all_labels, TRAIN_FRAC, VAL_FRAC, TEST_FRAC, SEED)\n",
        "\n",
        "# -------------------------\n",
        "# PRINTS + VALIDACIÓN FUERTE\n",
        "# -------------------------\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "print(\"Num clases:\", num_classes)\n",
        "print(\"Total ejemplos:\", len(all_files))\n",
        "print(\"\\nConteo por clase (primeras 20):\")\n",
        "for cls, n in per_class[:20]:\n",
        "    print(f\"  {cls:<30s} {n}\")\n",
        "if len(per_class) > 20:\n",
        "    print(\"  ...\")\n",
        "\n",
        "if len(all_files) == 0:\n",
        "    raise ValueError(\n",
        "        \"No se encontró ningún archivo de imagen válido en las carpetas.\\n\"\n",
        "        f\"DATA_DIR={DATA_DIR}\"\n",
        "    )\n",
        "\n",
        "print(\"\\nSplit tamaños:\", \"train\", len(train_idx), \"| val\", len(val_idx), \"| test\", len(test_idx))\n",
        "# Modificado: Solo se lanza un error si train_idx o val_idx están vacíos.\n",
        "# test_idx puede estar vacío si TEST_FRAC es 0.0, lo cual es intencional en ciertos escenarios.\n",
        "if len(train_idx) == 0 or len(val_idx) == 0:\n",
        "    raise ValueError(\n",
        "        \"Alguno de los splits de entrenamiento o validación quedó vacío. Revisa que haya suficientes ejemplos.\\n\"\n",
        "        f\"train={len(train_idx)}, val={len(val_idx)}, test={len(test_idx)}\"\n",
        "    )\n",
        "\n",
        "# Desbalance (usa TRAIN)\n",
        "train_labels = all_labels[train_idx]\n",
        "class_counts, class_weight = compute_class_weight(train_labels, num_classes)\n",
        "\n",
        "min_count = int(class_counts.min()) if len(class_counts) else 0\n",
        "max_count = int(class_counts.max()) if len(class_counts) else 0\n",
        "imbalance_ratio = (max_count / min_count) if (min_count > 0) else float(\"inf\")\n",
        "\n",
        "IMBALANCED = (imbalance_ratio >= 2.0) or (min_count <= 10)\n",
        "\n",
        "TINY_CLASS_THRESHOLD = 5\n",
        "RARE_CLASS_THRESHOLD = 10\n",
        "\n",
        "tiny_idx = np.where(class_counts <= TINY_CLASS_THRESHOLD)[0]\n",
        "rare_idx = np.where((class_counts > TINY_CLASS_THRESHOLD) & (class_counts <= RARE_CLASS_THRESHOLD))[0]\n",
        "zero_idx = np.where(class_counts == 0)[0]\n",
        "\n",
        "HAS_TINY_CLASSES = len(tiny_idx) > 0\n",
        "HAS_RARE_CLASSES = len(rare_idx) > 0\n",
        "\n",
        "USE_CLASS_WEIGHT = IMBALANCED or HAS_TINY_CLASSES or HAS_RARE_CLASSES\n",
        "MONITOR_METRIC = \"val_loss\" if (IMBALANCED or HAS_TINY_CLASSES) else \"val_accuracy\"\n",
        "\n",
        "print(\"\\nDistribución TRAIN: min\", min_count, \"| max\", max_count, \"| ratio\", imbalance_ratio)\n",
        "print(\"IMBALANCED:\", IMBALANCED)\n",
        "print(\"HAS_TINY_CLASSES:\", HAS_TINY_CLASSES, \"| HAS_RARE_CLASSES:\", HAS_RARE_CLASSES)\n",
        "print(\"USE_CLASS_WEIGHT:\", USE_CLASS_WEIGHT)\n",
        "print(\"MONITOR_METRIC:\", MONITOR_METRIC)\n",
        "\n",
        "print(\"\\n=== SANITY CHECK SPLITS ===\")\n",
        "print(\"Labels min/max:\", int(all_labels.min()), int(all_labels.max()))\n",
        "print(\"Num clases declarado:\", num_classes)\n",
        "\n",
        "def bincountK(y, K):\n",
        "    return np.bincount(y, minlength=K)\n",
        "\n",
        "print(\"Train per class:\", bincountK(all_labels[train_idx], num_classes).tolist())\n",
        "print(\"Val   per class:\", bincountK(all_labels[val_idx],   num_classes).tolist())\n",
        "print(\"Test  per class:\", bincountK(all_labels[test_idx],  num_classes).tolist())\n"
      ],
      "metadata": {
        "id": "hOByzwWQjFVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2379c6f5-1ca1-414c-a16c-b0ccf1bf7c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA_DIR: /content/dataset/simpsons_dataset\n",
            "Num clases: 14\n",
            "Total ejemplos: 17210\n",
            "\n",
            "Conteo por clase (primeras 20):\n",
            "  abraham_grampa_simpson         913\n",
            "  apu_nahasapeemapetilon         623\n",
            "  bart_simpson                   1342\n",
            "  charles_montgomery_burns       1193\n",
            "  chief_wiggum                   986\n",
            "  homer_simpson                  2246\n",
            "  krusty_the_clown               1206\n",
            "  lisa_simpson                   1354\n",
            "  marge_simpson                  1291\n",
            "  milhouse_van_houten            1079\n",
            "  moe_szyslak                    1452\n",
            "  ned_flanders                   1454\n",
            "  principal_skinner              1194\n",
            "  sideshow_bob                   877\n",
            "\n",
            "Split tamaños: train 10326 | val 3442 | test 3442\n",
            "\n",
            "Distribución TRAIN: min 374 | max 1348 | ratio 3.6042780748663104\n",
            "IMBALANCED: True\n",
            "HAS_TINY_CLASSES: False | HAS_RARE_CLASSES: False\n",
            "USE_CLASS_WEIGHT: True\n",
            "MONITOR_METRIC: val_loss\n",
            "\n",
            "=== SANITY CHECK SPLITS ===\n",
            "Labels min/max: 0 13\n",
            "Num clases declarado: 14\n",
            "Train per class: [548, 374, 805, 716, 592, 1348, 724, 812, 775, 647, 871, 872, 716, 526]\n",
            "Val   per class: [183, 125, 268, 239, 197, 449, 241, 271, 258, 216, 290, 291, 239, 175]\n",
            "Test  per class: [182, 124, 269, 238, 197, 449, 241, 271, 258, 216, 291, 291, 239, 176]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "#@title ## 2. AUTO-CONFIG (IMG_SIZE + BATCH) + CHANNELS (IMAGEN)\n",
        "# ==========================================================\n",
        "import math\n",
        "import PIL.Image\n",
        "\n",
        "def choose_img_size_and_batch(sample_shape, t4=True):\n",
        "    H, W, C = sample_shape\n",
        "    m = min(H, W)\n",
        "    if m <= 32:\n",
        "        img = (32, 32);  batch = 256\n",
        "    elif m <= 96:\n",
        "        img = (96, 96);  batch = 64\n",
        "    else:\n",
        "        img = (128, 128); batch = 32\n",
        "    return img, batch, C\n",
        "\n",
        "# ---- Inferir shape/canales con una muestra ----\n",
        "p0 = all_files[0]\n",
        "im = np.array(PIL.Image.open(p0))\n",
        "if im.ndim == 2:\n",
        "    H, W = im.shape\n",
        "    C = 1\n",
        "else:\n",
        "    H, W, C = im.shape\n",
        "sample_shape = (H, W, C)\n",
        "\n",
        "if AUTO:\n",
        "    IMG_SIZE, BATCH, CHANNELS = choose_img_size_and_batch(sample_shape, t4=True)\n",
        "else:\n",
        "    IMG_SIZE = IMG_SIZE_MANUAL\n",
        "    BATCH = BATCH_MANUAL\n",
        "    CHANNELS = 3  # si tus imágenes son RGB; si son grises, cambia a 1\n",
        "\n",
        "print(\"AUTO:\", AUTO)\n",
        "print(\"IMG_SIZE:\", IMG_SIZE)\n",
        "print(\"BATCH:\", BATCH)\n",
        "print(\"CHANNELS:\", CHANNELS)\n"
      ],
      "metadata": {
        "id": "gVmukbHEjIRJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d260378a-0ab3-4c01-c9e1-1ff8ae8bb223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUTO: True\n",
            "IMG_SIZE: (128, 128)\n",
            "BATCH: 32\n",
            "CHANNELS: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "#@title ## 3. PIPELINE IMAGEN (tf.data) + build_datasets(batch)\n",
        "# ==========================================================\n",
        "import tensorflow as tf\n",
        "\n",
        "def decode_image(path, label, img_size, channels):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.io.decode_image(img, channels=channels, expand_animations=False)\n",
        "    img = tf.image.resize(img, img_size, antialias=True)\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img, label\n",
        "\n",
        "def make_image_ds(files, labels, img_size, channels, batch, training=False, seed=123):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((files, labels))\n",
        "    if training:\n",
        "        ds = ds.shuffle(len(files), seed=seed, reshuffle_each_iteration=True)\n",
        "    ds = ds.map(lambda p,y: decode_image(p,y,img_size,channels), num_parallel_calls=AUTOTUNE)\n",
        "    ds = ds.batch(batch).prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "def build_datasets(batch):\n",
        "    train_ds = make_image_ds(all_files[train_idx], all_labels[train_idx], IMG_SIZE, CHANNELS, batch, training=True, seed=SEED)\n",
        "    val_ds   = make_image_ds(all_files[val_idx],   all_labels[val_idx],   IMG_SIZE, CHANNELS, batch, training=False)\n",
        "    test_ds  = make_image_ds(all_files[test_idx],  all_labels[test_idx],  IMG_SIZE, CHANNELS, batch, training=False)\n",
        "    return train_ds, val_ds, test_ds\n",
        "\n",
        "train_ds, val_ds, test_ds = build_datasets(BATCH)\n",
        "print(\"Datasets listos (imagen). BATCH =\", BATCH)\n"
      ],
      "metadata": {
        "id": "gBGCDVXgjCFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5374aa3-9c57-4349-f4b7-d99ccf87ce59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets listos (imagen). BATCH = 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "#@title ## 5. AUGMENT ROBUSTO (IMAGEN)\n",
        "# ==========================================================\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "augment = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.05),\n",
        "    layers.RandomZoom(0.10),\n",
        "], name=\"augment_image\")\n"
      ],
      "metadata": {
        "id": "i6kqduwRjPIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "#@title ## 6. MODELO CNN ROBUSTO (GAP + BN + Dropout)\n",
        "# ==========================================================\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "def build_cnn(img_size, channels, num_classes, augment_layer):\n",
        "    inputs = layers.Input(shape=(img_size[0], img_size[1], channels))\n",
        "    x = augment_layer(inputs)\n",
        "\n",
        "    x = layers.Conv2D(32, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.Conv2D(128, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.30)(x)\n",
        "\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
        "    return models.Model(inputs, outputs)\n",
        "\n",
        "model = build_cnn(IMG_SIZE, CHANNELS, num_classes, augment)\n",
        "\n",
        "metrics = [\"accuracy\"]\n",
        "if num_classes >= 10:\n",
        "    metrics.append(tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name=\"top5_acc\"))\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "xFeUbKiEjRaU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "outputId": "418a07a9-66e3-4611-95fa-a677bdb34a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ augment_image (\u001b[38;5;33mSequential\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │         \u001b[38;5;34m3,598\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ augment_image (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,598</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m130,766\u001b[0m (510.80 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130,766</span> (510.80 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m130,318\u001b[0m (509.05 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130,318</span> (509.05 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CELDA 7 — TRAIN (OOM-safe + class_weight + política robusta)\n",
        "# ==========================================================\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "if HAS_TINY_CLASSES:\n",
        "    LR = 5e-4\n",
        "    PATIENCE = 8\n",
        "else:\n",
        "    LR = 1e-3\n",
        "    PATIENCE = 5\n",
        "\n",
        "try:\n",
        "    model.optimizer.learning_rate.assign(LR)\n",
        "except Exception:\n",
        "    model.optimizer.learning_rate = LR\n",
        "\n",
        "print(\"LR usado:\", LR)\n",
        "print(\"PATIENCE usado:\", PATIENCE)\n",
        "print(\"MONITOR_METRIC:\", MONITOR_METRIC)\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=MONITOR_METRIC,\n",
        "        patience=PATIENCE,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"/content/weights.best.keras\",\n",
        "        monitor=MONITOR_METRIC,\n",
        "        save_best_only=True\n",
        "    )\n",
        "]\n",
        "\n",
        "fit_class_weight = class_weight if USE_CLASS_WEIGHT else None\n",
        "\n",
        "def batch_candidates(b0):\n",
        "    cands = [int(b0)]\n",
        "    while cands[-1] > 8:\n",
        "        cands.append(cands[-1] // 2)\n",
        "    cands = sorted(set([b for b in cands if b >= 8]), reverse=True)\n",
        "    return cands\n",
        "\n",
        "BATCH_TRIES = batch_candidates(BATCH)\n",
        "print(\"BATCH tries:\", BATCH_TRIES)\n",
        "\n",
        "history = None\n",
        "last_err = None\n",
        "\n",
        "for b_try in BATCH_TRIES:\n",
        "    try:\n",
        "        train_ds, val_ds, test_ds = build_datasets(b_try)\n",
        "\n",
        "        print(f\"\\nEntrenando con BATCH={b_try} | monitor={MONITOR_METRIC} | class_weight={USE_CLASS_WEIGHT}\")\n",
        "        history = model.fit(\n",
        "            train_ds,\n",
        "            validation_data=val_ds,\n",
        "            epochs=30,\n",
        "            callbacks=callbacks,\n",
        "            class_weight=fit_class_weight\n",
        "        )\n",
        "        BATCH = b_try\n",
        "        last_err = None\n",
        "        break\n",
        "\n",
        "    except tf.errors.ResourceExhaustedError as e:\n",
        "        last_err = e\n",
        "        print(f\"\\n⚠️ OOM con BATCH={b_try}. Reintentando con batch menor...\")\n",
        "        try:\n",
        "            del train_ds, val_ds, test_ds\n",
        "        except Exception:\n",
        "            pass\n",
        "        gc.collect()\n",
        "\n",
        "if history is None and last_err is not None:\n",
        "    raise last_err\n",
        "\n",
        "print(\"\\n✅ Entrenamiento finalizado. BATCH final usado:\", BATCH)\n",
        "\n",
        "# -------------------------\n",
        "# INFORME DE EPOCH FINAL (REAL)\n",
        "# -------------------------\n",
        "hist = history.history\n",
        "mon = MONITOR_METRIC\n",
        "\n",
        "if mon in hist:\n",
        "    if \"acc\" in mon:\n",
        "        best_epoch = int(np.argmax(hist[mon]) + 1)\n",
        "        best_value = float(np.max(hist[mon]))\n",
        "        mode = \"max\"\n",
        "    else:\n",
        "        best_epoch = int(np.argmin(hist[mon]) + 1)\n",
        "        best_value = float(np.min(hist[mon]))\n",
        "        mode = \"min\"\n",
        "\n",
        "    print(\"\\n📌 RESUMEN DE ENTRENAMIENTO\")\n",
        "    print(f\"Monitor usado      : {mon} ({mode})\")\n",
        "    print(f\"Epoch seleccionado : {best_epoch}\")\n",
        "    print(f\"Mejor {mon}        : {best_value:.4f}\")\n",
        "    print(\"✔ restore_best_weights=True → el modelo en memoria quedó en ese epoch\")\n",
        "else:\n",
        "    print(\"\\n⚠️ No se pudo determinar el epoch final (monitor no encontrado).\")\n",
        "    print(\"Keys disponibles:\", list(hist.keys()))\n"
      ],
      "metadata": {
        "id": "WZTWdIO2jTvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cbbbbb4-dd14-4300-b40f-58c132650733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR usado: 0.001\n",
            "PATIENCE usado: 5\n",
            "MONITOR_METRIC: val_loss\n",
            "BATCH tries: [32, 16, 8]\n",
            "\n",
            "Entrenando con BATCH=32 | monitor=val_loss | class_weight=True\n",
            "Epoch 1/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 112ms/step - accuracy: 0.1901 - loss: 2.3860 - top5_acc: 0.6016 - val_accuracy: 0.1775 - val_loss: 2.6739 - val_top5_acc: 0.4791\n",
            "Epoch 2/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 110ms/step - accuracy: 0.3360 - loss: 1.9391 - top5_acc: 0.7842 - val_accuracy: 0.2199 - val_loss: 2.7845 - val_top5_acc: 0.6781\n",
            "Epoch 3/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 96ms/step - accuracy: 0.4356 - loss: 1.6533 - top5_acc: 0.8440 - val_accuracy: 0.1360 - val_loss: 4.9712 - val_top5_acc: 0.5569\n",
            "Epoch 4/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.5067 - loss: 1.4756 - top5_acc: 0.8825 - val_accuracy: 0.5012 - val_loss: 1.5563 - val_top5_acc: 0.8765\n",
            "Epoch 5/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 98ms/step - accuracy: 0.5564 - loss: 1.2836 - top5_acc: 0.9115 - val_accuracy: 0.4648 - val_loss: 1.6942 - val_top5_acc: 0.8780\n",
            "Epoch 6/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.5958 - loss: 1.1740 - top5_acc: 0.9227 - val_accuracy: 0.5119 - val_loss: 1.4454 - val_top5_acc: 0.9085\n",
            "Epoch 7/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.6324 - loss: 1.0890 - top5_acc: 0.9350 - val_accuracy: 0.6136 - val_loss: 1.2291 - val_top5_acc: 0.9210\n",
            "Epoch 8/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.6566 - loss: 1.0165 - top5_acc: 0.9372 - val_accuracy: 0.3053 - val_loss: 2.9971 - val_top5_acc: 0.7074\n",
            "Epoch 9/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 108ms/step - accuracy: 0.6846 - loss: 0.9261 - top5_acc: 0.9491 - val_accuracy: 0.5285 - val_loss: 1.4739 - val_top5_acc: 0.8733\n",
            "Epoch 10/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.6890 - loss: 0.9022 - top5_acc: 0.9467 - val_accuracy: 0.4954 - val_loss: 1.7079 - val_top5_acc: 0.8980\n",
            "Epoch 11/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 98ms/step - accuracy: 0.7059 - loss: 0.8460 - top5_acc: 0.9578 - val_accuracy: 0.4666 - val_loss: 1.9027 - val_top5_acc: 0.9221\n",
            "Epoch 12/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 100ms/step - accuracy: 0.7266 - loss: 0.8226 - top5_acc: 0.9609 - val_accuracy: 0.6194 - val_loss: 1.1750 - val_top5_acc: 0.9390\n",
            "Epoch 13/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 105ms/step - accuracy: 0.7369 - loss: 0.7571 - top5_acc: 0.9638 - val_accuracy: 0.5790 - val_loss: 1.3815 - val_top5_acc: 0.9149\n",
            "Epoch 14/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.7485 - loss: 0.7336 - top5_acc: 0.9682 - val_accuracy: 0.4962 - val_loss: 1.8618 - val_top5_acc: 0.8701\n",
            "Epoch 15/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 108ms/step - accuracy: 0.7681 - loss: 0.6925 - top5_acc: 0.9687 - val_accuracy: 0.7423 - val_loss: 0.8019 - val_top5_acc: 0.9654\n",
            "Epoch 16/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 99ms/step - accuracy: 0.7701 - loss: 0.6676 - top5_acc: 0.9693 - val_accuracy: 0.6917 - val_loss: 1.0153 - val_top5_acc: 0.9372\n",
            "Epoch 17/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 96ms/step - accuracy: 0.7780 - loss: 0.6285 - top5_acc: 0.9760 - val_accuracy: 0.7223 - val_loss: 0.9131 - val_top5_acc: 0.9538\n",
            "Epoch 18/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 108ms/step - accuracy: 0.7886 - loss: 0.6173 - top5_acc: 0.9737 - val_accuracy: 0.6650 - val_loss: 1.1968 - val_top5_acc: 0.9221\n",
            "Epoch 19/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 105ms/step - accuracy: 0.7939 - loss: 0.6114 - top5_acc: 0.9726 - val_accuracy: 0.5090 - val_loss: 1.9576 - val_top5_acc: 0.9329\n",
            "Epoch 20/30\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 100ms/step - accuracy: 0.8026 - loss: 0.5616 - top5_acc: 0.9787 - val_accuracy: 0.3879 - val_loss: 3.3076 - val_top5_acc: 0.8925\n",
            "\n",
            "✅ Entrenamiento finalizado. BATCH final usado: 32\n",
            "\n",
            "📌 RESUMEN DE ENTRENAMIENTO\n",
            "Monitor usado      : val_loss (min)\n",
            "Epoch seleccionado : 15\n",
            "Mejor val_loss        : 0.8019\n",
            "✔ restore_best_weights=True → el modelo en memoria quedó en ese epoch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CELDA 7.5 — DIAGNÓSTICO AUTOMÁTICO DEL ENTRENAMIENTO (mejorado)\n",
        "# ==========================================================\n",
        "import numpy as np\n",
        "\n",
        "def diagnose_training_v2(history, num_classes, monitor_metric=\"val_loss\", patience=None):\n",
        "    h = history.history\n",
        "    epochs_ran = len(next(iter(h.values()))) if len(h) else 0\n",
        "\n",
        "    def arr(key):\n",
        "        v = h.get(key, None)\n",
        "        return None if v is None else np.array(v, dtype=float)\n",
        "\n",
        "    acc   = arr(\"accuracy\")\n",
        "    vacc  = arr(\"val_accuracy\")\n",
        "    loss  = arr(\"loss\")\n",
        "    vloss = arr(\"val_loss\")\n",
        "\n",
        "    chance = 1.0 / float(num_classes) if num_classes else np.nan\n",
        "\n",
        "    mon = arr(monitor_metric)\n",
        "    if mon is None:\n",
        "        print(\"⚠️ No existe monitor_metric en history:\", monitor_metric)\n",
        "        print(\"Keys:\", list(h.keys()))\n",
        "        return\n",
        "\n",
        "    if \"acc\" in monitor_metric:\n",
        "        best_i = int(np.nanargmax(mon))\n",
        "        best_val = float(np.nanmax(mon))\n",
        "        mode = \"max\"\n",
        "    else:\n",
        "        best_i = int(np.nanargmin(mon))\n",
        "        best_val = float(np.nanmin(mon))\n",
        "        mode = \"min\"\n",
        "\n",
        "    def safe_get(a, i):\n",
        "        return float(a[i]) if a is not None and len(a) > i else np.nan\n",
        "\n",
        "    last_i = epochs_ran - 1\n",
        "\n",
        "    last_acc  = safe_get(acc, last_i)\n",
        "    last_vacc = safe_get(vacc, last_i)\n",
        "    last_loss = safe_get(loss, last_i)\n",
        "    last_vloss= safe_get(vloss, last_i)\n",
        "\n",
        "    best_acc  = safe_get(acc, best_i)\n",
        "    best_vacc = safe_get(vacc, best_i)\n",
        "    best_loss = safe_get(loss, best_i)\n",
        "    best_vloss= safe_get(vloss, best_i)\n",
        "\n",
        "    degrade_loss = (not np.isnan(best_vloss) and not np.isnan(last_vloss) and last_vloss > best_vloss * 1.15)\n",
        "    degrade_acc  = (not np.isnan(best_vacc) and not np.isnan(last_vacc) and last_vacc < best_vacc - 0.07)\n",
        "\n",
        "    gap_best = best_acc - best_vacc if (not np.isnan(best_acc) and not np.isnan(best_vacc)) else np.nan\n",
        "    gap_last = last_acc - last_vacc if (not np.isnan(last_acc) and not np.isnan(last_vacc)) else np.nan\n",
        "\n",
        "    def slope(a):\n",
        "        if a is None or len(a) < 6:\n",
        "            return np.nan\n",
        "        y = a[-5:]\n",
        "        x = np.arange(len(y), dtype=float)\n",
        "        return float(np.polyfit(x, y, 1)[0])\n",
        "\n",
        "    s_acc  = slope(acc)\n",
        "    s_vacc = slope(vacc)\n",
        "    s_loss = slope(loss)\n",
        "    s_vloss= slope(vloss)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"DIAGNÓSTICO 7.5 — RESUMEN (v2)\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Clases: {num_classes} | azar≈ {chance:.4f} | epochs corridos: {epochs_ran}\")\n",
        "    print(f\"Monitor: {monitor_metric} ({mode}) | best_epoch={best_i+1} | best={best_val:.4f}\")\n",
        "    if patience is not None:\n",
        "        print(f\"Patience: {patience}\")\n",
        "\n",
        "    print(\"\\n— En BEST epoch (lo que queda en memoria si restore_best_weights=True) —\")\n",
        "    print(f\"  acc={best_acc:.4f} | val_acc={best_vacc:.4f} | loss={best_loss:.4f} | val_loss={best_vloss:.4f}\")\n",
        "    print(f\"  gap(train-val) en BEST: {gap_best:.4f}\")\n",
        "\n",
        "    print(\"\\n— En ÚLTIMO epoch entrenado (solo para ver tendencia) —\")\n",
        "    print(f\"  acc={last_acc:.4f} | val_acc={last_vacc:.4f} | loss={last_loss:.4f} | val_loss={last_vloss:.4f}\")\n",
        "    print(f\"  gap(train-val) en ÚLTIMO: {gap_last:.4f}\")\n",
        "    print(f\"  slopes últimos 5: acc_tr={s_acc:.4f}, acc_val={s_vacc:.4f}, loss_tr={s_loss:.4f}, loss_val={s_vloss:.4f}\")\n",
        "\n",
        "    near_chance = chance + 0.03\n",
        "\n",
        "    if not np.isnan(best_vacc) and best_vacc <= near_chance:\n",
        "        print(\"\\n⚠️ VALIDACIÓN CERCA DE AZAR (pipeline/labels/split sospechoso)\")\n",
        "        print(\"Acciones: revisar DATA_DIR, clases, etiquetas, y que train/val/test tengan todas las clases.\")\n",
        "        return\n",
        "\n",
        "    if (not np.isnan(best_acc) and best_acc < 0.60) and (not np.isnan(best_vacc) and best_vacc < 0.60):\n",
        "        print(\"\\n🟡 SUBAPRENDIZAJE (UNDERFITTING)\")\n",
        "        print(\"Acciones: más capacidad, más epochs, revisar representación/IMG_SIZE, LR, etc.\")\n",
        "        return\n",
        "\n",
        "    if (degrade_loss or degrade_acc) and (not np.isnan(gap_best) and gap_best >= 0.12):\n",
        "        print(\"\\n🔴 OVERFITTING (MEMORIZACIÓN) DESPUÉS DEL BEST\")\n",
        "        print(\"Señal: el modelo mejoró y luego empeoró en validación.\")\n",
        "        print(\"Recomendaciones:\")\n",
        "        print(\"  - Quédate con el modelo del best_epoch (ya queda restaurado si restore_best_weights=True).\")\n",
        "        print(\"  - Baja patience (p.ej. 3–4) o limita epochs.\")\n",
        "        print(\"  - Aumenta augment y/o sube dropout.\")\n",
        "        print(\"  - Si hay duplicados muy parecidos: split por grupo (escena/personaje/objeto).\")\n",
        "        return\n",
        "\n",
        "    if (not np.isnan(best_vacc) and best_vacc > chance + 0.20) and (not np.isnan(gap_best) and gap_best <= 0.12):\n",
        "        print(\"\\n✅ TODO BIEN / GENERALIZA RAZONABLEMENTE\")\n",
        "        print(\"Recomendaciones leves: afinar LR, scheduler, o un poco más de capacidad.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n🟢 MIXTO (pero NO roto): aprende, con margen de mejora\")\n",
        "    print(\"Sugerencias:\")\n",
        "    print(\"  - Si gap es alto: más regularización/augment o stopping más agresivo.\")\n",
        "    print(\"  - Si val se estanca: LR menor o scheduler.\")\n",
        "    print(\"Nota: si restore_best_weights=True, el modelo final es el del best_epoch.\")\n",
        "\n",
        "diagnose_training_v2(history, num_classes=num_classes, monitor_metric=MONITOR_METRIC, patience=PATIENCE)\n"
      ],
      "metadata": {
        "id": "KPvT_JrdmvT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deac0735-e5cf-4080-8954-fc81e238b499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DIAGNÓSTICO 7.5 — RESUMEN (v2)\n",
            "============================================================\n",
            "Clases: 14 | azar≈ 0.0714 | epochs corridos: 20\n",
            "Monitor: val_loss (min) | best_epoch=15 | best=0.8019\n",
            "Patience: 5\n",
            "\n",
            "— En BEST epoch (lo que queda en memoria si restore_best_weights=True) —\n",
            "  acc=0.7670 | val_acc=0.7423 | loss=0.6922 | val_loss=0.8019\n",
            "  gap(train-val) en BEST: 0.0247\n",
            "\n",
            "— En ÚLTIMO epoch entrenado (solo para ver tendencia) —\n",
            "  acc=0.8044 | val_acc=0.3879 | loss=0.5725 | val_loss=3.3076\n",
            "  gap(train-val) en ÚLTIMO: 0.4165\n",
            "  slopes últimos 5: acc_tr=0.0091, acc_val=-0.0821, loss_tr=-0.0250, loss_val=0.5629\n",
            "\n",
            "✅ TODO BIEN / GENERALIZA RAZONABLEMENTE\n",
            "Recomendaciones leves: afinar LR, scheduler, o un poco más de capacidad.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CELDA 8 — EVALUACIÓN EN TEST\n",
        "# ==========================================================\n",
        "test_out = model.evaluate(test_ds, verbose=0)\n",
        "print(\"TEST metrics:\")\n",
        "for name, val in zip(model.metrics_names, test_out):\n",
        "    print(f\"  {name:>12s}: {val:.4f}\")\n"
      ],
      "metadata": {
        "id": "lbVPmtNgmzGx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfcb9e54-4d8a-4342-ff3b-c2bc21a1222c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST metrics:\n",
            "          loss: 0.8175\n",
            "  compile_metrics: 0.7440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CELDA 9 — REPORTE + MATRIZ DE CONFUSIÓN\n",
        "# ==========================================================\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "for x, y in test_ds:\n",
        "    p = model.predict(x, verbose=0)\n",
        "    y_true.extend(y.numpy().tolist())\n",
        "    y_pred.extend(np.argmax(p, axis=1).tolist())\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"Matriz de confusión shape:\", cm.shape)\n",
        "\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=classes, digits=4))\n"
      ],
      "metadata": {
        "id": "GfvJcBxKm31d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "369b641b-0232-43d0-ebec-7e81d98b3cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de confusión shape: (14, 14)\n",
            "\n",
            "Classification report:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "  abraham_grampa_simpson     0.6711    0.8407    0.7463       182\n",
            "  apu_nahasapeemapetilon     0.8492    0.8629    0.8560       124\n",
            "            bart_simpson     0.5630    0.7138    0.6295       269\n",
            "charles_montgomery_burns     0.4437    0.8277    0.5777       238\n",
            "            chief_wiggum     0.8777    0.8376    0.8571       197\n",
            "           homer_simpson     0.8122    0.7127    0.7592       449\n",
            "        krusty_the_clown     0.8199    0.9253    0.8694       241\n",
            "            lisa_simpson     0.5452    0.6458    0.5912       271\n",
            "           marge_simpson     0.9349    0.7791    0.8499       258\n",
            "     milhouse_van_houten     0.8681    0.9444    0.9047       216\n",
            "             moe_szyslak     0.8249    0.5017    0.6239       291\n",
            "            ned_flanders     0.9636    0.7285    0.8297       291\n",
            "       principal_skinner     0.9494    0.6276    0.7557       239\n",
            "            sideshow_bob     0.9431    0.6591    0.7759       176\n",
            "\n",
            "                accuracy                         0.7440      3442\n",
            "               macro avg     0.7904    0.7576    0.7590      3442\n",
            "            weighted avg     0.7872    0.7440    0.7505      3442\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CELDA 10 — EXPORTAR \"resultados.zip\" (inferencia reproducible)\n",
        "# Contiene:\n",
        "#   - model.keras (modelo completo)\n",
        "#   - weights.best.keras (pesos del mejor checkpoint, si existe)\n",
        "#   - metadata.json (config + clases + parámetros)\n",
        "#   - infer_from_zip.py (script para predecir un ZIP nuevo)\n",
        "#   - README_INFERENCIA.txt (guía rápida)\n",
        "# Salida: /content/resultados.zip\n",
        "# ==========================================================\n",
        "import os, json, zipfile, shutil, time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "OUT_ZIP = \"/content/resultados.zip\"\n",
        "BUNDLE_DIR = \"/content/_bundle_resultados\"\n",
        "\n",
        "# Limpia bundle\n",
        "if os.path.isdir(BUNDLE_DIR):\n",
        "    shutil.rmtree(BUNDLE_DIR)\n",
        "os.makedirs(BUNDLE_DIR, exist_ok=True)\n",
        "\n",
        "# 1) Guardar modelo completo (incluye arquitectura + pesos actuales en memoria)\n",
        "MODEL_PATH = os.path.join(BUNDLE_DIR, \"model.keras\")\n",
        "model.save(MODEL_PATH)\n",
        "\n",
        "# 2) Copiar checkpoint best si existe\n",
        "WEIGHTS_SRC = \"/content/weights.best.keras\"\n",
        "WEIGHTS_DST = os.path.join(BUNDLE_DIR, \"weights.best.keras\")\n",
        "if os.path.isfile(WEIGHTS_SRC):\n",
        "    shutil.copy2(WEIGHTS_SRC, WEIGHTS_DST)\n",
        "\n",
        "# 3) Guardar metadata\n",
        "meta = {\n",
        "    \"created_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"zip_train_source\": os.path.basename(zip_name) if \"zip_name\" in globals() else None,\n",
        "    \"data_dir_train\": DATA_DIR if \"DATA_DIR\" in globals() else None,\n",
        "    \"seed\": int(SEED),\n",
        "    \"train_frac\": float(TRAIN_FRAC),\n",
        "    \"val_frac\": float(VAL_FRAC),\n",
        "    \"test_frac\": float(TEST_FRAC),\n",
        "    \"auto\": bool(AUTO),\n",
        "    \"img_size\": [int(IMG_SIZE[0]), int(IMG_SIZE[1])],\n",
        "    \"channels\": int(CHANNELS),\n",
        "    \"batch_final\": int(BATCH),\n",
        "    \"num_classes\": int(num_classes),\n",
        "    \"classes\": list(classes),\n",
        "    \"normalize\": \"x/255.0\",\n",
        "    \"decoder\": \"tf.io.decode_image(channels=CHANNELS, expand_animations=False)\",\n",
        "    \"resize\": \"tf.image.resize(img_size, antialias=True)\",\n",
        "    \"prediction\": {\n",
        "        \"type\": \"multiclass\",\n",
        "        \"activation\": \"softmax\",\n",
        "        \"label_type\": \"int index -> classes[index]\"\n",
        "    }\n",
        "}\n",
        "with open(os.path.join(BUNDLE_DIR, \"metadata.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# 4) Script de inferencia desde un ZIP nuevo\n",
        "infer_py = r'''\n",
        "import os, glob, zipfile, shutil, json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "WORKDIR = \"/content/new_zip_workdir\"\n",
        "EXTS = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n",
        "\n",
        "def find_images_root(workdir):\n",
        "    # Permite: raíz con imágenes, o subcarpetas con imágenes (cualquier profundidad 1)\n",
        "    candidates = [workdir] + [os.path.join(workdir, d) for d in os.listdir(workdir) if os.path.isdir(os.path.join(workdir, d))]\n",
        "\n",
        "    def score_dir(d):\n",
        "        if not os.path.isdir(d): return (-1, -1)\n",
        "        n = 0\n",
        "        for ext in EXTS:\n",
        "            n += len(glob.glob(os.path.join(d, f\"*{ext}\")))\n",
        "        # si tiene subcarpetas, suma también imágenes dentro de cada subcarpeta (1 nivel)\n",
        "        subdirs = [os.path.join(d, s) for s in os.listdir(d) if os.path.isdir(os.path.join(d, s))]\n",
        "        n2 = 0\n",
        "        for sd in subdirs:\n",
        "            for ext in EXTS:\n",
        "                n2 += len(glob.glob(os.path.join(sd, f\"*{ext}\")))\n",
        "        return (n, n2)\n",
        "\n",
        "    best = None\n",
        "    best_sc = (-1, -1)\n",
        "    for c in candidates:\n",
        "        sc = score_dir(c)\n",
        "        if sc > best_sc:\n",
        "            best_sc = sc\n",
        "            best = c\n",
        "    if best is None or (best_sc[0] + best_sc[1]) == 0:\n",
        "        raise ValueError(f\"No se encontraron imágenes en {workdir}\")\n",
        "    return best\n",
        "\n",
        "def list_all_images(root_dir):\n",
        "    # Si root_dir tiene imágenes directas, usa esas; si no, usa todas las subcarpetas (1 nivel)\n",
        "    direct = []\n",
        "    for ext in EXTS:\n",
        "        direct += glob.glob(os.path.join(root_dir, f\"*{ext}\"))\n",
        "    direct = sorted(direct)\n",
        "    if len(direct) > 0:\n",
        "        return direct\n",
        "\n",
        "    files = []\n",
        "    subdirs = [os.path.join(root_dir, s) for s in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, s))]\n",
        "    for sd in sorted(subdirs):\n",
        "        for ext in EXTS:\n",
        "            files += glob.glob(os.path.join(sd, f\"*{ext}\"))\n",
        "    return sorted(files)\n",
        "\n",
        "def decode_image(path, img_size, channels):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.io.decode_image(img, channels=channels, expand_animations=False)\n",
        "    img = tf.image.resize(img, img_size, antialias=True)\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img\n",
        "\n",
        "def make_ds(files, img_size, channels, batch):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(files)\n",
        "    ds = ds.map(lambda p: decode_image(p, img_size, channels), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "def predict_zip(zip_path, model_path=\"model.keras\", metadata_path=\"metadata.json\", out_csv=\"/content/predicciones.csv\"):\n",
        "    # Cargar metadata\n",
        "    with open(metadata_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        meta = json.load(f)\n",
        "    img_size = tuple(meta[\"img_size\"])\n",
        "    channels = int(meta[\"channels\"])\n",
        "    classes = meta[\"classes\"]\n",
        "    batch = int(meta.get(\"batch_final\", 32))\n",
        "\n",
        "    # Preparar workdir\n",
        "    if os.path.isdir(WORKDIR):\n",
        "        shutil.rmtree(WORKDIR)\n",
        "    os.makedirs(WORKDIR, exist_ok=True)\n",
        "\n",
        "    # Extraer zip\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "        z.extractall(WORKDIR)\n",
        "\n",
        "    # Detectar raíz con imágenes\n",
        "    root = find_images_root(WORKDIR)\n",
        "    files = list_all_images(root)\n",
        "    if len(files) == 0:\n",
        "        raise ValueError(\"No se encontraron imágenes para predecir.\")\n",
        "\n",
        "    # Cargar modelo\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Predicción\n",
        "    ds = make_ds(files, img_size, channels, batch)\n",
        "    probs = model.predict(ds, verbose=0)\n",
        "    pred_idx = np.argmax(probs, axis=1)\n",
        "    pred_name = [classes[i] for i in pred_idx]\n",
        "    conf = np.max(probs, axis=1)\n",
        "\n",
        "    # Guardar CSV\n",
        "    import csv\n",
        "    with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        w = csv.writer(f)\n",
        "        w.writerow([\"filepath\", \"pred_idx\", \"pred_class\", \"confidence\"])\n",
        "        for p, i, c, cf in zip(files, pred_idx, pred_name, conf):\n",
        "            w.writerow([p, int(i), c, float(cf)])\n",
        "\n",
        "    print(\"OK ✅\")\n",
        "    print(\"ZIP:\", zip_path)\n",
        "    print(\"Imágenes:\", len(files))\n",
        "    print(\"Salida CSV:\", out_csv)\n",
        "    return out_csv\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Usa el ZIP más reciente en /content por defecto\n",
        "    zips = sorted(glob.glob(\"/content/*.zip\"), key=os.path.getmtime)\n",
        "    assert len(zips) > 0, \"No hay ZIP en /content\"\n",
        "    zip_path = zips[-1]\n",
        "    predict_zip(zip_path)\n",
        "'''\n",
        "with open(os.path.join(BUNDLE_DIR, \"infer_from_zip.py\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(infer_py.strip() + \"\\n\")\n",
        "\n",
        "# 5) README mínimo\n",
        "readme = f\"\"\"\\\n",
        "RESULTADOS — INFERENCIA DESDE UN ZIP NUEVO (IMÁGENES)\n",
        "\n",
        "Archivos:\n",
        "- model.keras            : modelo completo (arquitectura + pesos en memoria)\n",
        "- weights.best.keras     : checkpoint best (si existe)\n",
        "- metadata.json          : IMG_SIZE, CHANNELS, classes, etc.\n",
        "- infer_from_zip.py      : script de predicción para un ZIP nuevo\n",
        "\n",
        "USO EN COLAB:\n",
        "1) Sube resultados.zip a /content y descomprímelo:\n",
        "   !unzip -o /content/resultados.zip -d /content/resultados\n",
        "\n",
        "2) Sube un ZIP NUEVO de imágenes a /content (ej: nuevo.zip)\n",
        "\n",
        "3) Corre:\n",
        "   %cd /content/resultados\n",
        "   !python infer_from_zip.py\n",
        "\n",
        "Salida:\n",
        "- /content/predicciones.csv\n",
        "\"\"\"\n",
        "with open(os.path.join(BUNDLE_DIR, \"README_INFERENCIA.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(readme)\n",
        "\n",
        "# 6) Empaquetar resultados.zip\n",
        "if os.path.isfile(OUT_ZIP):\n",
        "    os.remove(OUT_ZIP)\n",
        "\n",
        "with zipfile.ZipFile(OUT_ZIP, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
        "    for root, _, files in os.walk(BUNDLE_DIR):\n",
        "        for fn in files:\n",
        "            abs_path = os.path.join(root, fn)\n",
        "            rel_path = os.path.relpath(abs_path, BUNDLE_DIR)\n",
        "            z.write(abs_path, rel_path)\n",
        "\n",
        "print(\"✅ Creado:\", OUT_ZIP)\n",
        "!ls -lah /content/resultados.zip\n"
      ],
      "metadata": {
        "id": "xf-xGlGhpZ-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0053faf-11f1-44f7-ae17-33f17a23a018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Creado: /content/resultados.zip\n",
            "-rw-r--r-- 1 root root 4.7M Jan 20 23:55 /content/resultados.zip\n"
          ]
        }
      ]
    }
  ]
}