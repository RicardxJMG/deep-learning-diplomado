{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/datasets/\"\n",
        "SELECTED_ZIP_FILENAME = \"fashion_mnist.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6iQbHMFWYxZ",
        "outputId": "3d413578-de3b-4541-f297-1a11383549e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# NOTEBOOK: Clasificación de IMÁGENES + CNN\n",
        "# Robustez: split por archivos, class_weight automático, OOM-safe (T4),\n",
        "#           persistencia (weights.best.keras)\n",
        "#\n",
        "# ENTRADA:\n",
        "#   1) Subes un ZIP manualmente al runtime de Colab (/content/*.zip)\n",
        "#   2) Estructura interna del ZIP (recomendado):\n",
        "#        <raiz>/\n",
        "#          clase_0/   (jpg/png/...)\n",
        "#          clase_1/\n",
        "#          ...\n",
        "#\n",
        "# SALIDAS:\n",
        "#   - weights.best.keras\n",
        "# ============================================================\n",
        "\n",
        "# =========================\n",
        "# CELDA 0 — CONFIG GLOBAL + ZIP → WORKDIR + autodetección DATA_DIR\n",
        "# Supuesto: SIEMPRE subes un .zip manualmente al runtime (/content)\n",
        "# =========================\n",
        "import os, glob, zipfile, shutil, random, math, time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# -------------------------\n",
        "# 1) CONFIGURACIÓN GENERAL (SOLO IMAGEN)\n",
        "# -------------------------\n",
        "WORKDIR = \"/content/dataset\"\n",
        "CLEAN_WORKDIR = True\n",
        "\n",
        "DRIVE_DATA_SOURCE = os.path.join(DRIVE_PATH, 'fashion_mnist')\n",
        "\n",
        "SEED = 123\n",
        "TRAIN_FRAC = 0.70\n",
        "VAL_FRAC   = 0.15\n",
        "TEST_FRAC  = 0.15\n",
        "\n",
        "AUTO = True\n",
        "IMG_SIZE_MANUAL = (128, 128)   # si AUTO=False\n",
        "BATCH_MANUAL    = 32           # si AUTO=False\n",
        "\n",
        "# -------------------------\n",
        "# 2) OPTIMIZACIÓN GPU T4\n",
        "# -------------------------\n",
        "USE_MIXED_PRECISION = True\n",
        "if USE_MIXED_PRECISION:\n",
        "    try:\n",
        "        from tensorflow.keras import mixed_precision\n",
        "        mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "        print(\"Mixed precision activada:\", mixed_precision.global_policy())\n",
        "    except Exception as e:\n",
        "        print(\"No se pudo activar mixed precision:\", e)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 3) DETECTAR ZIP EN DRIVE Y COPIAR/DESCOMPRIMIR\n",
        "# -------------------------\n",
        "# Usar SELECTED_ZIP_FILENAME definido en la celda anterior\n",
        "zip_name_full_path = os.path.join(DRIVE_DATA_SOURCE, SELECTED_ZIP_FILENAME)\n",
        "assert os.path.exists(zip_name_full_path), f\"No se encontró el archivo ZIP '{SELECTED_ZIP_FILENAME}' en {DRIVE_DATA_SOURCE}.\"\n",
        "zip_base_name = os.path.basename(zip_name_full_path)\n",
        "\n",
        "print(\"ZIP seleccionado en Drive:\", zip_base_name)\n",
        "print(\"Última modificación:\", time.ctime(os.path.getmtime(zip_name_full_path)))\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 4) PREPARAR WORKDIR Y DESCOMPRIMIR\n",
        "# -------------------------\n",
        "if CLEAN_WORKDIR and os.path.isdir(WORKDIR):\n",
        "    shutil.rmtree(WORKDIR)\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "\n",
        "print(f\"Descomprimiendo {zip_base_name} en {WORKDIR}...\")\n",
        "with zipfile.ZipFile(zip_name_full_path, \"r\") as z:\n",
        "    z.extractall(WORKDIR)\n",
        "\n",
        "print(\"Dataset descomprimido en:\", WORKDIR)\n",
        "!ls -lah \"{WORKDIR}\"\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 5) AUTODETECTAR DATA_DIR REAL\n",
        "#   buscamos una carpeta que contenga subcarpetas con archivos válidos\n",
        "# -------------------------\n",
        "def find_data_root_images(workdir):\n",
        "    exts = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n",
        "\n",
        "    candidates = [workdir]\n",
        "    candidates += [os.path.join(workdir, d) for d in os.listdir(workdir) if os.path.isdir(os.path.join(workdir, d))]\n",
        "\n",
        "    def score_dir(d):\n",
        "        if not os.path.isdir(d):\n",
        "            return -1, 0, 0\n",
        "        subdirs = [os.path.join(d, s) for s in os.listdir(d) if os.path.isdir(os.path.join(d, s))]\n",
        "        if not subdirs:\n",
        "            return -1, 0, 0\n",
        "\n",
        "        good_folders = 0\n",
        "        total_files = 0\n",
        "        for sd in subdirs:\n",
        "            n = 0\n",
        "            for ext in exts:\n",
        "                n += len(glob.glob(os.path.join(sd, f\"*{ext}\")))\n",
        "            if n > 0:\n",
        "                good_folders += 1\n",
        "                total_files += n\n",
        "        return good_folders, total_files, len(subdirs)\n",
        "\n",
        "    best = None\n",
        "    best_score = (-1, -1, -1)\n",
        "    for c in candidates:\n",
        "        sc = score_dir(c)\n",
        "        if sc > best_score:\n",
        "            best_score = sc\n",
        "            best = c\n",
        "\n",
        "    if best is None or best_score[0] < 2:\n",
        "        raise ValueError(\n",
        "            \"No pude detectar una raíz de dataset válida.\\n\"\n",
        "            \"Asegúrate de que el ZIP contenga una carpeta con subcarpetas y archivos de imagen.\\n\"\n",
        "            f\"WORKDIR={workdir}\"\n",
        "        )\n",
        "\n",
        "    return best, best_score\n",
        "\n",
        "DATA_DIR, sc = find_data_root_images(WORKDIR)\n",
        "\n",
        "print(\"\\nCONFIG FINAL:\")\n",
        "print(\"  WORKDIR   :\", WORKDIR)\n",
        "print(\"  DATA_DIR  :\", DATA_DIR)\n",
        "print(\"  (folders_con_archivos, total_archivos, subcarpetas):\", sc)\n",
        "print(\"  GPU       :\", tf.config.list_physical_devices(\"GPU\"))\n"
      ],
      "metadata": {
        "id": "ugkPYVSui6KQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b757ce-0d68-4e0b-840f-4d5fd7aa9280"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mixed precision activada: <DTypePolicy \"mixed_float16\">\n",
            "ZIP seleccionado en Drive: fashion_mnist.zip\n",
            "Última modificación: Mon Jan 12 21:42:45 2026\n",
            "Descomprimiendo fashion_mnist.zip en /content/dataset...\n",
            "Dataset descomprimido en: /content/dataset\n",
            "total 2.2M\n",
            "drwxr-xr-x 12 root root 4.0K Jan 21 07:20 .\n",
            "drwxr-xr-x  1 root root 4.0K Jan 21 07:19 ..\n",
            "drwxr-xr-x  2 root root 216K Jan 21 07:20 0\n",
            "drwxr-xr-x  2 root root 228K Jan 21 07:20 1\n",
            "drwxr-xr-x  2 root root 204K Jan 21 07:20 2\n",
            "drwxr-xr-x  2 root root 204K Jan 21 07:20 3\n",
            "drwxr-xr-x  2 root root 216K Jan 21 07:20 4\n",
            "drwxr-xr-x  2 root root 220K Jan 21 07:20 5\n",
            "drwxr-xr-x  2 root root 224K Jan 21 07:19 6\n",
            "drwxr-xr-x  2 root root 220K Jan 21 07:20 7\n",
            "drwxr-xr-x  2 root root 200K Jan 21 07:20 8\n",
            "drwxr-xr-x  2 root root 200K Jan 21 07:20 9\n",
            "\n",
            "CONFIG FINAL:\n",
            "  WORKDIR   : /content/dataset\n",
            "  DATA_DIR  : /content/dataset\n",
            "  (folders_con_archivos, total_archivos, subcarpetas): (10, 70000, 10)\n",
            "  GPU       : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# CELDA 1 — UTILIDADES: CLASES + SPLIT + DESBALANCE + VALIDACIÓN FUERTE (IMAGEN)\n",
        "# ======================================\n",
        "import numpy as np\n",
        "import os, glob\n",
        "\n",
        "def list_class_folders(data_dir):\n",
        "    classes = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
        "    if len(classes) < 2:\n",
        "        raise ValueError(f\"Se requieren >=2 subcarpetas en: {data_dir}. Encontré: {classes}\")\n",
        "    return classes\n",
        "\n",
        "def list_files_by_class_image(data_dir):\n",
        "    classes = list_class_folders(data_dir)\n",
        "    exts = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n",
        "\n",
        "    files = []\n",
        "    labels = []\n",
        "    per_class = []\n",
        "\n",
        "    for i, cls in enumerate(classes):\n",
        "        cls_dir = os.path.join(data_dir, cls)\n",
        "        cls_files = []\n",
        "        for ext in exts:\n",
        "            cls_files.extend(glob.glob(os.path.join(cls_dir, f\"*{ext}\")))\n",
        "        cls_files = sorted(cls_files)\n",
        "\n",
        "        per_class.append((cls, len(cls_files)))\n",
        "        files.extend(cls_files)\n",
        "        labels.extend([i]*len(cls_files))\n",
        "\n",
        "    return classes, np.array(files), np.array(labels, dtype=np.int32), per_class\n",
        "\n",
        "def stratified_split(files, labels, train_frac, val_frac, test_frac, seed=123):\n",
        "    assert abs(train_frac + val_frac + test_frac - 1.0) < 1e-9\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx = np.arange(len(files))\n",
        "\n",
        "    train_idx, val_idx, test_idx = [], [], []\n",
        "    for c in np.unique(labels):\n",
        "        c_idx = idx[labels == c]\n",
        "        rng.shuffle(c_idx)\n",
        "        n = len(c_idx)\n",
        "        if n == 0:\n",
        "            continue\n",
        "\n",
        "        n_train = int(round(n * train_frac))\n",
        "        n_val   = int(round(n * val_frac))\n",
        "\n",
        "        n_train = max(1, min(n_train, n))\n",
        "        n_val = min(n_val, n - n_train)\n",
        "\n",
        "        train_idx.extend(c_idx[:n_train])\n",
        "        val_idx.extend(c_idx[n_train:n_train+n_val])\n",
        "        test_idx.extend(c_idx[n_train+n_val:])\n",
        "\n",
        "    rng.shuffle(train_idx); rng.shuffle(val_idx); rng.shuffle(test_idx)\n",
        "    return np.array(train_idx), np.array(val_idx), np.array(test_idx)\n",
        "\n",
        "def compute_class_weight(train_labels, num_classes):\n",
        "    counts = np.bincount(train_labels, minlength=num_classes).astype(np.int64)\n",
        "    N = counts.sum()\n",
        "    weights = {}\n",
        "    for c in range(num_classes):\n",
        "        weights[c] = 0.0 if counts[c] == 0 else float(N) / float(num_classes * counts[c])\n",
        "    return counts, weights\n",
        "\n",
        "# -------------------------\n",
        "# CARGA (IMAGEN)\n",
        "# -------------------------\n",
        "classes, all_files, all_labels, per_class = list_files_by_class_image(DATA_DIR)\n",
        "num_classes = len(classes)\n",
        "\n",
        "train_idx, val_idx, test_idx = stratified_split(all_files, all_labels, TRAIN_FRAC, VAL_FRAC, TEST_FRAC, SEED)\n",
        "\n",
        "# -------------------------\n",
        "# PRINTS + VALIDACIÓN FUERTE\n",
        "# -------------------------\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "print(\"Num clases:\", num_classes)\n",
        "print(\"Total ejemplos:\", len(all_files))\n",
        "print(\"\\nConteo por clase (primeras 20):\")\n",
        "for cls, n in per_class[:20]:\n",
        "    print(f\"  {cls:<30s} {n}\")\n",
        "if len(per_class) > 20:\n",
        "    print(\"  ...\")\n",
        "\n",
        "if len(all_files) == 0:\n",
        "    raise ValueError(\n",
        "        \"No se encontró ningún archivo de imagen válido en las carpetas.\\n\"\n",
        "        f\"DATA_DIR={DATA_DIR}\"\n",
        "    )\n",
        "\n",
        "print(\"\\nSplit tamaños:\", \"train\", len(train_idx), \"| val\", len(val_idx), \"| test\", len(test_idx))\n",
        "if len(train_idx) == 0 or len(val_idx) == 0 or len(test_idx) == 0:\n",
        "    raise ValueError(\n",
        "        \"Alguno de los splits quedó vacío. Revisa que haya suficientes ejemplos.\\n\"\n",
        "        f\"train={len(train_idx)}, val={len(val_idx)}, test={len(test_idx)}\"\n",
        "    )\n",
        "\n",
        "# Desbalance (usa TRAIN)\n",
        "train_labels = all_labels[train_idx]\n",
        "class_counts, class_weight = compute_class_weight(train_labels, num_classes)\n",
        "\n",
        "min_count = int(class_counts.min()) if len(class_counts) else 0\n",
        "max_count = int(class_counts.max()) if len(class_counts) else 0\n",
        "imbalance_ratio = (max_count / min_count) if (min_count > 0) else float(\"inf\")\n",
        "\n",
        "IMBALANCED = (imbalance_ratio >= 2.0) or (min_count <= 10)\n",
        "\n",
        "TINY_CLASS_THRESHOLD = 5\n",
        "RARE_CLASS_THRESHOLD = 10\n",
        "\n",
        "tiny_idx = np.where(class_counts <= TINY_CLASS_THRESHOLD)[0]\n",
        "rare_idx = np.where((class_counts > TINY_CLASS_THRESHOLD) & (class_counts <= RARE_CLASS_THRESHOLD))[0]\n",
        "zero_idx = np.where(class_counts == 0)[0]\n",
        "\n",
        "HAS_TINY_CLASSES = len(tiny_idx) > 0\n",
        "HAS_RARE_CLASSES = len(rare_idx) > 0\n",
        "\n",
        "USE_CLASS_WEIGHT = IMBALANCED or HAS_TINY_CLASSES or HAS_RARE_CLASSES\n",
        "MONITOR_METRIC = \"val_loss\" if (IMBALANCED or HAS_TINY_CLASSES) else \"val_accuracy\"\n",
        "\n",
        "print(\"\\nDistribución TRAIN: min\", min_count, \"| max\", max_count, \"| ratio\", imbalance_ratio)\n",
        "print(\"IMBALANCED:\", IMBALANCED)\n",
        "print(\"HAS_TINY_CLASSES:\", HAS_TINY_CLASSES, \"| HAS_RARE_CLASSES:\", HAS_RARE_CLASSES)\n",
        "print(\"USE_CLASS_WEIGHT:\", USE_CLASS_WEIGHT)\n",
        "print(\"MONITOR_METRIC:\", MONITOR_METRIC)\n",
        "\n",
        "print(\"\\n=== SANITY CHECK SPLITS ===\")\n",
        "print(\"Labels min/max:\", int(all_labels.min()), int(all_labels.max()))\n",
        "print(\"Num clases declarado:\", num_classes)\n",
        "\n",
        "def bincountK(y, K):\n",
        "    return np.bincount(y, minlength=K)\n",
        "\n",
        "print(\"Train per class:\", bincountK(all_labels[train_idx], num_classes).tolist())\n",
        "print(\"Val   per class:\", bincountK(all_labels[val_idx],   num_classes).tolist())\n",
        "print(\"Test  per class:\", bincountK(all_labels[test_idx],  num_classes).tolist())\n"
      ],
      "metadata": {
        "id": "hOByzwWQjFVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94ab4077-b49e-42da-a5ba-8eff7ed4f0b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA_DIR: /content/dataset\n",
            "Num clases: 10\n",
            "Total ejemplos: 70000\n",
            "\n",
            "Conteo por clase (primeras 20):\n",
            "  0                              7000\n",
            "  1                              7000\n",
            "  2                              7000\n",
            "  3                              7000\n",
            "  4                              7000\n",
            "  5                              7000\n",
            "  6                              7000\n",
            "  7                              7000\n",
            "  8                              7000\n",
            "  9                              7000\n",
            "\n",
            "Split tamaños: train 49000 | val 10500 | test 10500\n",
            "\n",
            "Distribución TRAIN: min 4900 | max 4900 | ratio 1.0\n",
            "IMBALANCED: False\n",
            "HAS_TINY_CLASSES: False | HAS_RARE_CLASSES: False\n",
            "USE_CLASS_WEIGHT: False\n",
            "MONITOR_METRIC: val_accuracy\n",
            "\n",
            "=== SANITY CHECK SPLITS ===\n",
            "Labels min/max: 0 9\n",
            "Num clases declarado: 10\n",
            "Train per class: [4900, 4900, 4900, 4900, 4900, 4900, 4900, 4900, 4900, 4900]\n",
            "Val   per class: [1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050]\n",
            "Test  per class: [1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050, 1050]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CELDA 2 — AUTO-CONFIG (IMG_SIZE + BATCH) + CHANNELS (IMAGEN)\n",
        "# ==========================================================\n",
        "import math\n",
        "import PIL.Image\n",
        "\n",
        "def choose_img_size_and_batch(sample_shape, t4=True):\n",
        "    H, W, C = sample_shape\n",
        "    m = min(H, W)\n",
        "    if m <= 32:\n",
        "        img = (32, 32);  batch = 256\n",
        "    elif m <= 96:\n",
        "        img = (96, 96);  batch = 64\n",
        "    else:\n",
        "        img = (128, 128); batch = 32\n",
        "    return img, batch, C\n",
        "\n",
        "# ---- Inferir shape/canales con una muestra ----\n",
        "p0 = all_files[0]\n",
        "im = np.array(PIL.Image.open(p0))\n",
        "if im.ndim == 2:\n",
        "    H, W = im.shape\n",
        "    C = 1\n",
        "else:\n",
        "    H, W, C = im.shape\n",
        "sample_shape = (H, W, C)\n",
        "\n",
        "if AUTO:\n",
        "    IMG_SIZE, BATCH, CHANNELS = choose_img_size_and_batch(sample_shape, t4=True)\n",
        "else:\n",
        "    IMG_SIZE = IMG_SIZE_MANUAL\n",
        "    BATCH = BATCH_MANUAL\n",
        "    CHANNELS = 3  # si tus imágenes son RGB; si son grises, cambia a 1\n",
        "\n",
        "print(\"AUTO:\", AUTO)\n",
        "print(\"IMG_SIZE:\", IMG_SIZE)\n",
        "print(\"BATCH:\", BATCH)\n",
        "print(\"CHANNELS:\", CHANNELS)\n"
      ],
      "metadata": {
        "id": "gVmukbHEjIRJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa82b10d-44c2-4424-9ef1-3dcb659d96bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUTO: True\n",
            "IMG_SIZE: (32, 32)\n",
            "BATCH: 256\n",
            "CHANNELS: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CELDA 3 — PIPELINE IMAGEN (tf.data) + build_datasets(batch)\n",
        "# ==========================================================\n",
        "import tensorflow as tf\n",
        "\n",
        "def decode_image(path, label, img_size, channels):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.io.decode_image(img, channels=channels, expand_animations=False)\n",
        "    img = tf.image.resize(img, img_size, antialias=True)\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img, label\n",
        "\n",
        "def make_image_ds(files, labels, img_size, channels, batch, training=False, seed=123):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((files, labels))\n",
        "    if training:\n",
        "        ds = ds.shuffle(len(files), seed=seed, reshuffle_each_iteration=True)\n",
        "    ds = ds.map(lambda p,y: decode_image(p,y,img_size,channels), num_parallel_calls=AUTOTUNE)\n",
        "    ds = ds.batch(batch).prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "def build_datasets(batch):\n",
        "    train_ds = make_image_ds(all_files[train_idx], all_labels[train_idx], IMG_SIZE, CHANNELS, batch, training=True, seed=SEED)\n",
        "    val_ds   = make_image_ds(all_files[val_idx],   all_labels[val_idx],   IMG_SIZE, CHANNELS, batch, training=False)\n",
        "    test_ds  = make_image_ds(all_files[test_idx],  all_labels[test_idx],  IMG_SIZE, CHANNELS, batch, training=False)\n",
        "    return train_ds, val_ds, test_ds\n",
        "\n",
        "train_ds, val_ds, test_ds = build_datasets(BATCH)\n",
        "print(\"Datasets listos (imagen). BATCH =\", BATCH)\n"
      ],
      "metadata": {
        "id": "gBGCDVXgjCFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae2f0d3-9d22-471c-f539-30630c64eaf2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets listos (imagen). BATCH = 256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CELDA 5 — AUGMENT ROBUSTO (IMAGEN)\n",
        "# ==========================================================\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "augment = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.05),\n",
        "    layers.RandomZoom(0.10),\n",
        "], name=\"augment_image\")\n"
      ],
      "metadata": {
        "id": "i6kqduwRjPIv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CELDA 6 — MODELO CNN ROBUSTO (GAP + BN + Dropout)\n",
        "# ==========================================================\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "def build_cnn(img_size, channels, num_classes, augment_layer):\n",
        "    inputs = layers.Input(shape=(img_size[0], img_size[1], channels))\n",
        "    x = augment_layer(inputs)\n",
        "\n",
        "    x = layers.Conv2D(32, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.Conv2D(128, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.30)(x)\n",
        "\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
        "    return models.Model(inputs, outputs)\n",
        "\n",
        "model = build_cnn(IMG_SIZE, CHANNELS, num_classes, augment)\n",
        "\n",
        "metrics = [\"accuracy\"]\n",
        "if num_classes >= 10:\n",
        "    metrics.append(tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name=\"top5_acc\"))\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "xFeUbKiEjRaU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "outputId": "a0b340ad-1e1d-4b42-d85c-91004eae6718"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ augment_image (\u001b[38;5;33mSequential\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ augment_image (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m129,162\u001b[0m (504.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,162</span> (504.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m128,714\u001b[0m (502.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,714</span> (502.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CELDA 7 — TRAIN (OOM-safe + class_weight + política robusta)\n",
        "# ==========================================================\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "if HAS_TINY_CLASSES:\n",
        "    LR = 5e-4\n",
        "    PATIENCE = 8\n",
        "else:\n",
        "    LR = 1e-3\n",
        "    PATIENCE = 5\n",
        "\n",
        "try:\n",
        "    model.optimizer.learning_rate.assign(LR)\n",
        "except Exception:\n",
        "    model.optimizer.learning_rate = LR\n",
        "\n",
        "print(\"LR usado:\", LR)\n",
        "print(\"PATIENCE usado:\", PATIENCE)\n",
        "print(\"MONITOR_METRIC:\", MONITOR_METRIC)\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=MONITOR_METRIC,\n",
        "        patience=PATIENCE,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"/content/weights.best.keras\",\n",
        "        monitor=MONITOR_METRIC,\n",
        "        save_best_only=True\n",
        "    )\n",
        "]\n",
        "\n",
        "fit_class_weight = class_weight if USE_CLASS_WEIGHT else None\n",
        "\n",
        "def batch_candidates(b0):\n",
        "    cands = [int(b0)]\n",
        "    while cands[-1] > 8:\n",
        "        cands.append(cands[-1] // 2)\n",
        "    cands = sorted(set([b for b in cands if b >= 8]), reverse=True)\n",
        "    return cands\n",
        "\n",
        "BATCH_TRIES = batch_candidates(BATCH)\n",
        "print(\"BATCH tries:\", BATCH_TRIES)\n",
        "\n",
        "history = None\n",
        "last_err = None\n",
        "\n",
        "for b_try in BATCH_TRIES:\n",
        "    try:\n",
        "        train_ds, val_ds, test_ds = build_datasets(b_try)\n",
        "\n",
        "        print(f\"\\nEntrenando con BATCH={b_try} | monitor={MONITOR_METRIC} | class_weight={USE_CLASS_WEIGHT}\")\n",
        "        history = model.fit(\n",
        "            train_ds,\n",
        "            validation_data=val_ds,\n",
        "            epochs=30,\n",
        "            callbacks=callbacks,\n",
        "            class_weight=fit_class_weight\n",
        "        )\n",
        "        BATCH = b_try\n",
        "        last_err = None\n",
        "        break\n",
        "\n",
        "    except tf.errors.ResourceExhaustedError as e:\n",
        "        last_err = e\n",
        "        print(f\"\\n⚠️ OOM con BATCH={b_try}. Reintentando con batch menor...\")\n",
        "        try:\n",
        "            del train_ds, val_ds, test_ds\n",
        "        except Exception:\n",
        "            pass\n",
        "        gc.collect()\n",
        "\n",
        "if history is None and last_err is not None:\n",
        "    raise last_err\n",
        "\n",
        "print(\"\\n✅ Entrenamiento finalizado. BATCH final usado:\", BATCH)\n",
        "\n",
        "# -------------------------\n",
        "# INFORME DE EPOCH FINAL (REAL)\n",
        "# -------------------------\n",
        "hist = history.history\n",
        "mon = MONITOR_METRIC\n",
        "\n",
        "if mon in hist:\n",
        "    if \"acc\" in mon:\n",
        "        best_epoch = int(np.argmax(hist[mon]) + 1)\n",
        "        best_value = float(np.max(hist[mon]))\n",
        "        mode = \"max\"\n",
        "    else:\n",
        "        best_epoch = int(np.argmin(hist[mon]) + 1)\n",
        "        best_value = float(np.min(hist[mon]))\n",
        "        mode = \"min\"\n",
        "\n",
        "    print(\"\\n📌 RESUMEN DE ENTRENAMIENTO\")\n",
        "    print(f\"Monitor usado      : {mon} ({mode})\")\n",
        "    print(f\"Epoch seleccionado : {best_epoch}\")\n",
        "    print(f\"Mejor {mon}        : {best_value:.4f}\")\n",
        "    print(\"✔ restore_best_weights=True → el modelo en memoria quedó en ese epoch\")\n",
        "else:\n",
        "    print(\"\\n⚠️ No se pudo determinar el epoch final (monitor no encontrado).\")\n",
        "    print(\"Keys disponibles:\", list(hist.keys()))\n"
      ],
      "metadata": {
        "id": "WZTWdIO2jTvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a62909c1-a58f-4f07-bc86-f925b7f8a2d2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR usado: 0.001\n",
            "PATIENCE usado: 5\n",
            "MONITOR_METRIC: val_accuracy\n",
            "BATCH tries: [256, 128, 64, 32, 16, 8]\n",
            "\n",
            "Entrenando con BATCH=256 | monitor=val_accuracy | class_weight=False\n",
            "Epoch 1/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 96ms/step - accuracy: 0.5892 - loss: 1.1519 - top5_acc: 0.9359 - val_accuracy: 0.1677 - val_loss: 3.9466 - val_top5_acc: 0.5000\n",
            "Epoch 2/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.7957 - loss: 0.5647 - top5_acc: 0.9947 - val_accuracy: 0.2671 - val_loss: 2.2725 - val_top5_acc: 0.7455\n",
            "Epoch 3/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 89ms/step - accuracy: 0.8199 - loss: 0.4932 - top5_acc: 0.9955 - val_accuracy: 0.7907 - val_loss: 0.5732 - val_top5_acc: 0.9946\n",
            "Epoch 4/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.8356 - loss: 0.4503 - top5_acc: 0.9970 - val_accuracy: 0.8389 - val_loss: 0.4263 - val_top5_acc: 0.9962\n",
            "Epoch 5/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 81ms/step - accuracy: 0.8442 - loss: 0.4286 - top5_acc: 0.9967 - val_accuracy: 0.7925 - val_loss: 0.5901 - val_top5_acc: 0.9956\n",
            "Epoch 6/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 81ms/step - accuracy: 0.8521 - loss: 0.4053 - top5_acc: 0.9975 - val_accuracy: 0.8555 - val_loss: 0.4108 - val_top5_acc: 0.9959\n",
            "Epoch 7/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 81ms/step - accuracy: 0.8532 - loss: 0.4020 - top5_acc: 0.9972 - val_accuracy: 0.7929 - val_loss: 0.5619 - val_top5_acc: 0.9944\n",
            "Epoch 8/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 81ms/step - accuracy: 0.8631 - loss: 0.3784 - top5_acc: 0.9975 - val_accuracy: 0.8327 - val_loss: 0.4802 - val_top5_acc: 0.9962\n",
            "Epoch 9/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.8681 - loss: 0.3636 - top5_acc: 0.9984 - val_accuracy: 0.8360 - val_loss: 0.4497 - val_top5_acc: 0.9961\n",
            "Epoch 10/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.8711 - loss: 0.3582 - top5_acc: 0.9978 - val_accuracy: 0.8765 - val_loss: 0.3415 - val_top5_acc: 0.9972\n",
            "Epoch 11/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.8683 - loss: 0.3539 - top5_acc: 0.9986 - val_accuracy: 0.8487 - val_loss: 0.4178 - val_top5_acc: 0.9981\n",
            "Epoch 12/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 82ms/step - accuracy: 0.8738 - loss: 0.3436 - top5_acc: 0.9984 - val_accuracy: 0.8155 - val_loss: 0.5030 - val_top5_acc: 0.9978\n",
            "Epoch 13/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 88ms/step - accuracy: 0.8774 - loss: 0.3368 - top5_acc: 0.9986 - val_accuracy: 0.7778 - val_loss: 0.7069 - val_top5_acc: 0.9946\n",
            "Epoch 14/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 82ms/step - accuracy: 0.8805 - loss: 0.3292 - top5_acc: 0.9983 - val_accuracy: 0.8793 - val_loss: 0.3455 - val_top5_acc: 0.9982\n",
            "Epoch 15/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 82ms/step - accuracy: 0.8828 - loss: 0.3205 - top5_acc: 0.9986 - val_accuracy: 0.8829 - val_loss: 0.3234 - val_top5_acc: 0.9983\n",
            "Epoch 16/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 80ms/step - accuracy: 0.8790 - loss: 0.3286 - top5_acc: 0.9985 - val_accuracy: 0.8484 - val_loss: 0.4108 - val_top5_acc: 0.9981\n",
            "Epoch 17/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 80ms/step - accuracy: 0.8846 - loss: 0.3146 - top5_acc: 0.9988 - val_accuracy: 0.8762 - val_loss: 0.3556 - val_top5_acc: 0.9979\n",
            "Epoch 18/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.8869 - loss: 0.3105 - top5_acc: 0.9988 - val_accuracy: 0.8622 - val_loss: 0.3857 - val_top5_acc: 0.9970\n",
            "Epoch 19/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 87ms/step - accuracy: 0.8843 - loss: 0.3146 - top5_acc: 0.9984 - val_accuracy: 0.8835 - val_loss: 0.3325 - val_top5_acc: 0.9983\n",
            "Epoch 20/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.8865 - loss: 0.3030 - top5_acc: 0.9987 - val_accuracy: 0.7874 - val_loss: 0.6822 - val_top5_acc: 0.9936\n",
            "Epoch 21/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 81ms/step - accuracy: 0.8887 - loss: 0.3040 - top5_acc: 0.9989 - val_accuracy: 0.8706 - val_loss: 0.3520 - val_top5_acc: 0.9974\n",
            "Epoch 22/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.8908 - loss: 0.3010 - top5_acc: 0.9987 - val_accuracy: 0.8804 - val_loss: 0.3274 - val_top5_acc: 0.9982\n",
            "Epoch 23/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.8885 - loss: 0.3022 - top5_acc: 0.9987 - val_accuracy: 0.8811 - val_loss: 0.3596 - val_top5_acc: 0.9986\n",
            "Epoch 24/30\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - accuracy: 0.8923 - loss: 0.2891 - top5_acc: 0.9990 - val_accuracy: 0.8019 - val_loss: 0.5656 - val_top5_acc: 0.9977\n",
            "\n",
            "✅ Entrenamiento finalizado. BATCH final usado: 256\n",
            "\n",
            "📌 RESUMEN DE ENTRENAMIENTO\n",
            "Monitor usado      : val_accuracy (max)\n",
            "Epoch seleccionado : 19\n",
            "Mejor val_accuracy        : 0.8835\n",
            "✔ restore_best_weights=True → el modelo en memoria quedó en ese epoch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CELDA 7.5 — DIAGNÓSTICO AUTOMÁTICO DEL ENTRENAMIENTO (mejorado)\n",
        "# ==========================================================\n",
        "import numpy as np\n",
        "\n",
        "def diagnose_training_v2(history, num_classes, monitor_metric=\"val_loss\", patience=None):\n",
        "    h = history.history\n",
        "    epochs_ran = len(next(iter(h.values()))) if len(h) else 0\n",
        "\n",
        "    def arr(key):\n",
        "        v = h.get(key, None)\n",
        "        return None if v is None else np.array(v, dtype=float)\n",
        "\n",
        "    acc   = arr(\"accuracy\")\n",
        "    vacc  = arr(\"val_accuracy\")\n",
        "    loss  = arr(\"loss\")\n",
        "    vloss = arr(\"val_loss\")\n",
        "\n",
        "    chance = 1.0 / float(num_classes) if num_classes else np.nan\n",
        "\n",
        "    mon = arr(monitor_metric)\n",
        "    if mon is None:\n",
        "        print(\"⚠️ No existe monitor_metric en history:\", monitor_metric)\n",
        "        print(\"Keys:\", list(h.keys()))\n",
        "        return\n",
        "\n",
        "    if \"acc\" in monitor_metric:\n",
        "        best_i = int(np.nanargmax(mon))\n",
        "        best_val = float(np.nanmax(mon))\n",
        "        mode = \"max\"\n",
        "    else:\n",
        "        best_i = int(np.nanargmin(mon))\n",
        "        best_val = float(np.nanmin(mon))\n",
        "        mode = \"min\"\n",
        "\n",
        "    def safe_get(a, i):\n",
        "        return float(a[i]) if a is not None and len(a) > i else np.nan\n",
        "\n",
        "    last_i = epochs_ran - 1\n",
        "\n",
        "    last_acc  = safe_get(acc, last_i)\n",
        "    last_vacc = safe_get(vacc, last_i)\n",
        "    last_loss = safe_get(loss, last_i)\n",
        "    last_vloss= safe_get(vloss, last_i)\n",
        "\n",
        "    best_acc  = safe_get(acc, best_i)\n",
        "    best_vacc = safe_get(vacc, best_i)\n",
        "    best_loss = safe_get(loss, best_i)\n",
        "    best_vloss= safe_get(vloss, best_i)\n",
        "\n",
        "    degrade_loss = (not np.isnan(best_vloss) and not np.isnan(last_vloss) and last_vloss > best_vloss * 1.15)\n",
        "    degrade_acc  = (not np.isnan(best_vacc) and not np.isnan(last_vacc) and last_vacc < best_vacc - 0.07)\n",
        "\n",
        "    gap_best = best_acc - best_vacc if (not np.isnan(best_acc) and not np.isnan(best_vacc)) else np.nan\n",
        "    gap_last = last_acc - last_vacc if (not np.isnan(last_acc) and not np.isnan(last_vacc)) else np.nan\n",
        "\n",
        "    def slope(a):\n",
        "        if a is None or len(a) < 6:\n",
        "            return np.nan\n",
        "        y = a[-5:]\n",
        "        x = np.arange(len(y), dtype=float)\n",
        "        return float(np.polyfit(x, y, 1)[0])\n",
        "\n",
        "    s_acc  = slope(acc)\n",
        "    s_vacc = slope(vacc)\n",
        "    s_loss = slope(loss)\n",
        "    s_vloss= slope(vloss)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"DIAGNÓSTICO 7.5 — RESUMEN (v2)\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Clases: {num_classes} | azar≈ {chance:.4f} | epochs corridos: {epochs_ran}\")\n",
        "    print(f\"Monitor: {monitor_metric} ({mode}) | best_epoch={best_i+1} | best={best_val:.4f}\")\n",
        "    if patience is not None:\n",
        "        print(f\"Patience: {patience}\")\n",
        "\n",
        "    print(\"\\n— En BEST epoch (lo que queda en memoria si restore_best_weights=True) —\")\n",
        "    print(f\"  acc={best_acc:.4f} | val_acc={best_vacc:.4f} | loss={best_loss:.4f} | val_loss={best_vloss:.4f}\")\n",
        "    print(f\"  gap(train-val) en BEST: {gap_best:.4f}\")\n",
        "\n",
        "    print(\"\\n— En ÚLTIMO epoch entrenado (solo para ver tendencia) —\")\n",
        "    print(f\"  acc={last_acc:.4f} | val_acc={last_vacc:.4f} | loss={last_loss:.4f} | val_loss={last_vloss:.4f}\")\n",
        "    print(f\"  gap(train-val) en ÚLTIMO: {gap_last:.4f}\")\n",
        "    print(f\"  slopes últimos 5: acc_tr={s_acc:.4f}, acc_val={s_vacc:.4f}, loss_tr={s_loss:.4f}, loss_val={s_vloss:.4f}\")\n",
        "\n",
        "    near_chance = chance + 0.03\n",
        "\n",
        "    if not np.isnan(best_vacc) and best_vacc <= near_chance:\n",
        "        print(\"\\n⚠️ VALIDACIÓN CERCA DE AZAR (pipeline/labels/split sospechoso)\")\n",
        "        print(\"Acciones: revisar DATA_DIR, clases, etiquetas, y que train/val/test tengan todas las clases.\")\n",
        "        return\n",
        "\n",
        "    if (not np.isnan(best_acc) and best_acc < 0.60) and (not np.isnan(best_vacc) and best_vacc < 0.60):\n",
        "        print(\"\\n🟡 SUBAPRENDIZAJE (UNDERFITTING)\")\n",
        "        print(\"Acciones: más capacidad, más epochs, revisar representación/IMG_SIZE, LR, etc.\")\n",
        "        return\n",
        "\n",
        "    if (degrade_loss or degrade_acc) and (not np.isnan(gap_best) and gap_best >= 0.12):\n",
        "        print(\"\\n🔴 OVERFITTING (MEMORIZACIÓN) DESPUÉS DEL BEST\")\n",
        "        print(\"Señal: el modelo mejoró y luego empeoró en validación.\")\n",
        "        print(\"Recomendaciones:\")\n",
        "        print(\"  - Quédate con el modelo del best_epoch (ya queda restaurado si restore_best_weights=True).\")\n",
        "        print(\"  - Baja patience (p.ej. 3–4) o limita epochs.\")\n",
        "        print(\"  - Aumenta augment y/o sube dropout.\")\n",
        "        print(\"  - Si hay duplicados muy parecidos: split por grupo (escena/personaje/objeto).\")\n",
        "        return\n",
        "\n",
        "    if (not np.isnan(best_vacc) and best_vacc > chance + 0.20) and (not np.isnan(gap_best) and gap_best <= 0.12):\n",
        "        print(\"\\n✅ TODO BIEN / GENERALIZA RAZONABLEMENTE\")\n",
        "        print(\"Recomendaciones leves: afinar LR, scheduler, o un poco más de capacidad.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n🟢 MIXTO (pero NO roto): aprende, con margen de mejora\")\n",
        "    print(\"Sugerencias:\")\n",
        "    print(\"  - Si gap es alto: más regularización/augment o stopping más agresivo.\")\n",
        "    print(\"  - Si val se estanca: LR menor o scheduler.\")\n",
        "    print(\"Nota: si restore_best_weights=True, el modelo final es el del best_epoch.\")\n",
        "\n",
        "diagnose_training_v2(history, num_classes=num_classes, monitor_metric=MONITOR_METRIC, patience=PATIENCE)\n"
      ],
      "metadata": {
        "id": "KPvT_JrdmvT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6d1d18c-4d69-4ce2-fcaf-2ca3757c9d25"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DIAGNÓSTICO 7.5 — RESUMEN (v2)\n",
            "============================================================\n",
            "Clases: 10 | azar≈ 0.1000 | epochs corridos: 24\n",
            "Monitor: val_accuracy (max) | best_epoch=19 | best=0.8835\n",
            "Patience: 5\n",
            "\n",
            "— En BEST epoch (lo que queda en memoria si restore_best_weights=True) —\n",
            "  acc=0.8863 | val_acc=0.8835 | loss=0.3091 | val_loss=0.3325\n",
            "  gap(train-val) en BEST: 0.0028\n",
            "\n",
            "— En ÚLTIMO epoch entrenado (solo para ver tendencia) —\n",
            "  acc=0.8913 | val_acc=0.8019 | loss=0.2919 | val_loss=0.5656\n",
            "  gap(train-val) en ÚLTIMO: 0.0894\n",
            "  slopes últimos 5: acc_tr=0.0009, acc_val=0.0040, loss_tr=-0.0029, loss_val=-0.0225\n",
            "\n",
            "✅ TODO BIEN / GENERALIZA RAZONABLEMENTE\n",
            "Recomendaciones leves: afinar LR, scheduler, o un poco más de capacidad.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CELDA 8 — EVALUACIÓN EN TEST\n",
        "# ==========================================================\n",
        "test_out = model.evaluate(test_ds, verbose=0)\n",
        "print(\"TEST metrics:\")\n",
        "for name, val in zip(model.metrics_names, test_out):\n",
        "    print(f\"  {name:>12s}: {val:.4f}\")\n"
      ],
      "metadata": {
        "id": "lbVPmtNgmzGx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19e9fa46-34d1-482d-c770-14592987a858"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST metrics:\n",
            "          loss: 0.3376\n",
            "  compile_metrics: 0.8780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CELDA 9 — REPORTE + MATRIZ DE CONFUSIÓN\n",
        "# ==========================================================\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "for x, y in test_ds:\n",
        "    p = model.predict(x, verbose=0)\n",
        "    y_true.extend(y.numpy().tolist())\n",
        "    y_pred.extend(np.argmax(p, axis=1).tolist())\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"Matriz de confusión shape:\", cm.shape)\n",
        "\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=classes, digits=4))\n"
      ],
      "metadata": {
        "id": "GfvJcBxKm31d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dec0037-8100-4b3e-970e-9211fa4576d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de confusión shape: (10, 10)\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6859    0.9295    0.7893      1050\n",
            "           1     0.9837    0.9790    0.9814      1050\n",
            "           2     0.9245    0.7114    0.8041      1050\n",
            "           3     0.8491    0.9219    0.8840      1050\n",
            "           4     0.8315    0.8410    0.8362      1050\n",
            "           5     0.9969    0.9067    0.9496      1050\n",
            "           6     0.7746    0.6152    0.6858      1050\n",
            "           7     0.8551    0.9895    0.9174      1050\n",
            "           8     0.9790    0.9771    0.9781      1050\n",
            "           9     0.9835    0.9086    0.9446      1050\n",
            "\n",
            "    accuracy                         0.8780     10500\n",
            "   macro avg     0.8864    0.8780    0.8770     10500\n",
            "weighted avg     0.8864    0.8780    0.8770     10500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CELDA 10 — EXPORTAR \"resultados.zip\" (inferencia reproducible)\n",
        "# Contiene:\n",
        "#   - model.keras (modelo completo)\n",
        "#   - weights.best.keras (pesos del mejor checkpoint, si existe)\n",
        "#   - metadata.json (config + clases + parámetros)\n",
        "#   - infer_from_zip.py (script para predecir un ZIP nuevo)\n",
        "#   - README_INFERENCIA.txt (guía rápida)\n",
        "# Salida: /content/resultados.zip\n",
        "# ==========================================================\n",
        "import os, json, zipfile, shutil, time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "OUT_ZIP = \"/content/resultados.zip\"\n",
        "BUNDLE_DIR = \"/content/_bundle_resultados\"\n",
        "\n",
        "# Limpia bundle\n",
        "if os.path.isdir(BUNDLE_DIR):\n",
        "    shutil.rmtree(BUNDLE_DIR)\n",
        "os.makedirs(BUNDLE_DIR, exist_ok=True)\n",
        "\n",
        "# 1) Guardar modelo completo (incluye arquitectura + pesos actuales en memoria)\n",
        "MODEL_PATH = os.path.join(BUNDLE_DIR, \"model.keras\")\n",
        "model.save(MODEL_PATH)\n",
        "\n",
        "# 2) Copiar checkpoint best si existe\n",
        "WEIGHTS_SRC = \"/content/weights.best.keras\"\n",
        "WEIGHTS_DST = os.path.join(BUNDLE_DIR, \"weights.best.keras\")\n",
        "if os.path.isfile(WEIGHTS_SRC):\n",
        "    shutil.copy2(WEIGHTS_SRC, WEIGHTS_DST)\n",
        "\n",
        "# 3) Guardar metadata\n",
        "meta = {\n",
        "    \"created_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"zip_train_source\": os.path.basename(zip_name) if \"zip_name\" in globals() else None,\n",
        "    \"data_dir_train\": DATA_DIR if \"DATA_DIR\" in globals() else None,\n",
        "    \"seed\": int(SEED),\n",
        "    \"train_frac\": float(TRAIN_FRAC),\n",
        "    \"val_frac\": float(VAL_FRAC),\n",
        "    \"test_frac\": float(TEST_FRAC),\n",
        "    \"auto\": bool(AUTO),\n",
        "    \"img_size\": [int(IMG_SIZE[0]), int(IMG_SIZE[1])],\n",
        "    \"channels\": int(CHANNELS),\n",
        "    \"batch_final\": int(BATCH),\n",
        "    \"num_classes\": int(num_classes),\n",
        "    \"classes\": list(classes),\n",
        "    \"normalize\": \"x/255.0\",\n",
        "    \"decoder\": \"tf.io.decode_image(channels=CHANNELS, expand_animations=False)\",\n",
        "    \"resize\": \"tf.image.resize(img_size, antialias=True)\",\n",
        "    \"prediction\": {\n",
        "        \"type\": \"multiclass\",\n",
        "        \"activation\": \"softmax\",\n",
        "        \"label_type\": \"int index -> classes[index]\"\n",
        "    }\n",
        "}\n",
        "with open(os.path.join(BUNDLE_DIR, \"metadata.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# 4) Script de inferencia desde un ZIP nuevo\n",
        "infer_py = r'''\n",
        "import os, glob, zipfile, shutil, json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "WORKDIR = \"/content/new_zip_workdir\"\n",
        "EXTS = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n",
        "\n",
        "def find_images_root(workdir):\n",
        "    # Permite: raíz con imágenes, o subcarpetas con imágenes (cualquier profundidad 1)\n",
        "    candidates = [workdir] + [os.path.join(workdir, d) for d in os.listdir(workdir) if os.path.isdir(os.path.join(workdir, d))]\n",
        "\n",
        "    def score_dir(d):\n",
        "        if not os.path.isdir(d): return (-1, -1)\n",
        "        n = 0\n",
        "        for ext in EXTS:\n",
        "            n += len(glob.glob(os.path.join(d, f\"*{ext}\")))\n",
        "        # si tiene subcarpetas, suma también imágenes dentro de cada subcarpeta (1 nivel)\n",
        "        subdirs = [os.path.join(d, s) for s in os.listdir(d) if os.path.isdir(os.path.join(d, s))]\n",
        "        n2 = 0\n",
        "        for sd in subdirs:\n",
        "            for ext in EXTS:\n",
        "                n2 += len(glob.glob(os.path.join(sd, f\"*{ext}\")))\n",
        "        return (n, n2)\n",
        "\n",
        "    best = None\n",
        "    best_sc = (-1, -1)\n",
        "    for c in candidates:\n",
        "        sc = score_dir(c)\n",
        "        if sc > best_sc:\n",
        "            best_sc = sc\n",
        "            best = c\n",
        "    if best is None or (best_sc[0] + best_sc[1]) == 0:\n",
        "        raise ValueError(f\"No se encontraron imágenes en {workdir}\")\n",
        "    return best\n",
        "\n",
        "def list_all_images(root_dir):\n",
        "    # Si root_dir tiene imágenes directas, usa esas; si no, usa todas las subcarpetas (1 nivel)\n",
        "    direct = []\n",
        "    for ext in EXTS:\n",
        "        direct += glob.glob(os.path.join(root_dir, f\"*{ext}\"))\n",
        "    direct = sorted(direct)\n",
        "    if len(direct) > 0:\n",
        "        return direct\n",
        "\n",
        "    files = []\n",
        "    subdirs = [os.path.join(root_dir, s) for s in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, s))]\n",
        "    for sd in sorted(subdirs):\n",
        "        for ext in EXTS:\n",
        "            files += glob.glob(os.path.join(sd, f\"*{ext}\"))\n",
        "    return sorted(files)\n",
        "\n",
        "def decode_image(path, img_size, channels):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.io.decode_image(img, channels=channels, expand_animations=False)\n",
        "    img = tf.image.resize(img, img_size, antialias=True)\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img\n",
        "\n",
        "def make_ds(files, img_size, channels, batch):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(files)\n",
        "    ds = ds.map(lambda p: decode_image(p, img_size, channels), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "def predict_zip(zip_path, model_path=\"model.keras\", metadata_path=\"metadata.json\", out_csv=\"/content/predicciones.csv\"):\n",
        "    # Cargar metadata\n",
        "    with open(metadata_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        meta = json.load(f)\n",
        "    img_size = tuple(meta[\"img_size\"])\n",
        "    channels = int(meta[\"channels\"])\n",
        "    classes = meta[\"classes\"]\n",
        "    batch = int(meta.get(\"batch_final\", 32))\n",
        "\n",
        "    # Preparar workdir\n",
        "    if os.path.isdir(WORKDIR):\n",
        "        shutil.rmtree(WORKDIR)\n",
        "    os.makedirs(WORKDIR, exist_ok=True)\n",
        "\n",
        "    # Extraer zip\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "        z.extractall(WORKDIR)\n",
        "\n",
        "    # Detectar raíz con imágenes\n",
        "    root = find_images_root(WORKDIR)\n",
        "    files = list_all_images(root)\n",
        "    if len(files) == 0:\n",
        "        raise ValueError(\"No se encontraron imágenes para predecir.\")\n",
        "\n",
        "    # Cargar modelo\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Predicción\n",
        "    ds = make_ds(files, img_size, channels, batch)\n",
        "    probs = model.predict(ds, verbose=0)\n",
        "    pred_idx = np.argmax(probs, axis=1)\n",
        "    pred_name = [classes[i] for i in pred_idx]\n",
        "    conf = np.max(probs, axis=1)\n",
        "\n",
        "    # Guardar CSV\n",
        "    import csv\n",
        "    with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        w = csv.writer(f)\n",
        "        w.writerow([\"filepath\", \"pred_idx\", \"pred_class\", \"confidence\"])\n",
        "        for p, i, c, cf in zip(files, pred_idx, pred_name, conf):\n",
        "            w.writerow([p, int(i), c, float(cf)])\n",
        "\n",
        "    print(\"OK ✅\")\n",
        "    print(\"ZIP:\", zip_path)\n",
        "    print(\"Imágenes:\", len(files))\n",
        "    print(\"Salida CSV:\", out_csv)\n",
        "    return out_csv\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Usa el ZIP más reciente en /content por defecto\n",
        "    zips = sorted(glob.glob(\"/content/*.zip\"), key=os.path.getmtime)\n",
        "    assert len(zips) > 0, \"No hay ZIP en /content\"\n",
        "    zip_path = zips[-1]\n",
        "    predict_zip(zip_path)\n",
        "'''\n",
        "with open(os.path.join(BUNDLE_DIR, \"infer_from_zip.py\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(infer_py.strip() + \"\\n\")\n",
        "\n",
        "# 5) README mínimo\n",
        "readme = f\"\"\"\\\n",
        "RESULTADOS — INFERENCIA DESDE UN ZIP NUEVO (IMÁGENES)\n",
        "\n",
        "Archivos:\n",
        "- model.keras            : modelo completo (arquitectura + pesos en memoria)\n",
        "- weights.best.keras     : checkpoint best (si existe)\n",
        "- metadata.json          : IMG_SIZE, CHANNELS, classes, etc.\n",
        "- infer_from_zip.py      : script de predicción para un ZIP nuevo\n",
        "\n",
        "USO EN COLAB:\n",
        "1) Sube resultados.zip a /content y descomprímelo:\n",
        "   !unzip -o /content/resultados.zip -d /content/resultados\n",
        "\n",
        "2) Sube un ZIP NUEVO de imágenes a /content (ej: nuevo.zip)\n",
        "\n",
        "3) Corre:\n",
        "   %cd /content/resultados\n",
        "   !python infer_from_zip.py\n",
        "\n",
        "Salida:\n",
        "- /content/predicciones.csv\n",
        "\"\"\"\n",
        "with open(os.path.join(BUNDLE_DIR, \"README_INFERENCIA.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(readme)\n",
        "\n",
        "# 6) Empaquetar resultados.zip\n",
        "if os.path.isfile(OUT_ZIP):\n",
        "    os.remove(OUT_ZIP)\n",
        "\n",
        "with zipfile.ZipFile(OUT_ZIP, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
        "    for root, _, files in os.walk(BUNDLE_DIR):\n",
        "        for fn in files:\n",
        "            abs_path = os.path.join(root, fn)\n",
        "            rel_path = os.path.relpath(abs_path, BUNDLE_DIR)\n",
        "            z.write(abs_path, rel_path)\n",
        "\n",
        "print(\"✅ Creado:\", OUT_ZIP)\n",
        "!ls -lah /content/resultados.zip\n"
      ],
      "metadata": {
        "id": "xf-xGlGhpZ-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f89a3b7-9821-49c8-8cb8-ae6edfa92d2b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Creado: /content/resultados.zip\n",
            "-rw-r--r-- 1 root root 4.6M Jan 21 07:27 /content/resultados.zip\n"
          ]
        }
      ]
    }
  ]
}